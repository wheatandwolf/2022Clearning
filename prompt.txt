请基于【当前RAG应用后端完整代码】，按照如下需求进行变更，输出变更后的完整代码（不允许省略！！！注释用中文！！！）：
新增系统的参与者——管理员（管理员显然和一般的用户具有不同的权限，其中各方面的设计你应当参考【部分已经约定好的接口】，其他可以由你来决定，但是你具体做出了什么决定需要向我说明一下），管理员可以在平台上进行可视化的知识库管理，管理员可以在平台上进行已有知识库（原始形式）的查看，支持从系统上添加内容到知识库；包括但不限于： 数据格式扩展，支持pdf, html, md等各种格式的文件读取；特殊数据内容处理，例如pdf中的表格

部分已经约定好的接口：
目前前端接口写好了管理员的注册，比常规用户的注册增加了验证码字段；修改了login和getCurrentUser的逻辑，返回值增加了role字段。
1、
curl --location --request POST '/auth/adminRegister' \
--header 'Content-Type: application/json' \
--data-raw '{
    "email": "string",
    "username": "string",
    "password": "string",
    "verification": "string"
}'
相应：
/**
 * TokenResponse
 */
export interface Response {
    /**
     * 响应消息
     */
    message: string;
    role: Role;
    /**
     * 操作是否成功
     */
    success: boolean;
    /**
     * JWT 访问令牌
     */
    token?: string;
    /**
     * 用户 ID
     */
    user_id?: number;
    /**
     * 用户名
     */
    username?: string;
    [property: string]: any;
}

export enum Role {
    Admin = "ADMIN",
    User = "USER",
}

2、
curl --location --request POST '/auth/register' \
--header 'Content-Type: application/json' \
--data-raw '{
    "username": "string",
    "password": "string",
    "email": "user@example.com"
}'
响应：
/**
 * TokenResponse
 */
export interface Response {
    /**
     * 响应消息
     */
    message: string;
    role: Role;
    /**
     * 操作是否成功
     */
    success: boolean;
    /**
     * JWT 访问令牌
     */
    token?: string;
    /**
     * 用户 ID
     */
    user_id?: number;
    /**
     * 用户名
     */
    username?: string;
    [property: string]: any;
}

export enum Role {
    Admin = "ADMIN",
    User = "USER",
}

3、
curl --location --request POST '/auth/login' \
--header 'Content-Type: application/json' \
--data-raw '{
    "username": "string",
    "password": "string"
}'
响应：
/**
 * TokenResponse
 */
export interface Response {
    /**
     * 响应消息
     */
    message: string;
    role: Role;
    /**
     * 操作是否成功
     */
    success: boolean;
    /**
     * JWT 访问令牌
     */
    token?: string;
    /**
     * 用户 ID
     */
    user_id?: number;
    /**
     * 用户名
     */
    username?: string;
    [property: string]: any;
}

export enum Role {
    Admin = "ADMIN",
    User = "USER",
}

4、获取当前用户信息 /users/me
无请求参数
响应：
/**
 * UserResponse
 */
export interface Response {
    /**
     * 账户创建时间
     */
    created_at: Date;
    /**
     * 电子邮箱
     */
    email: string;
    role: Role;
    /**
     * 用户ID
     */
    user_id: number;
    /**
     * 用户名
     */
    username: string;
    [property: string]: any;
}

export enum Role {
    Admin = "ADMIN",
    User = "USER",
}
5、 管理员上传和查看数据库的api
import { AxiosResponse } from 'axios';
import httpService from './httpService';

export interface KnowledgeBaseItem {
  title: string;
  content: string;
}

export interface KnowledgeBaseResponse {
  content: KnowledgeBaseItem[];
  page_count: number;
}

export interface UploadKnowledgeBaseResponse {
  success: boolean;
}

/**
 * 分页获取某个知识库的内容
 * @param type 知识库种类
 * @param start_index 起始下标
 * @param page_size 每页大小
 * @returns AxiosResponse<KnowledgeBaseResponse>
 */
export const getKnowledgeBase = async (
  type: 'WIKI' | 'POST' | 'BBS' | 'MODE' | 'ITEM' | 'NEW',
  start_index: number,
  page_size: number
): Promise<AxiosResponse<KnowledgeBaseResponse>> => {
  return await httpService.post<KnowledgeBaseResponse>('/admin/getKnowledgeBase', {
    type,
    start_index,
    page_size
  });
};

/**
 * 上传知识库内容
 * @param dataArr 包含metadata（字符串数组）和file（File）的对象数组
 * @returns AxiosResponse<{success: boolean}>
 */
export const uploadKnowledgeBase = async (
  dataArr: { metadata: string[]; file: File }[]
): Promise<AxiosResponse<UploadKnowledgeBaseResponse>> => {
  const formData = new FormData();
  dataArr.forEach((item, idx) => {
    // metadata作为json字符串上传
    formData.append(`metadata[${idx}]`, JSON.stringify(item.metadata));
    // 文件
    formData.append(`file[${idx}]`, item.file);
  });
  return await httpService.post<UploadKnowledgeBaseResponse>(
    '/admin/uploadKnowledgeBase',
    formData,
    {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    }
  );
};

【完整前端ts参考】
rag-frontend\src\env.d.ts
/// <reference types="vite/client" />

/* 声明Vue模块 */
declare module '*.vue' {
  import type { DefineComponent } from 'vue'
  // 使用更严格的类型替代 {}, {}, any
  const component: DefineComponent<Record<string, unknown>, Record<string, unknown>, unknown>
  export default component
}

/* 声明静态资源模块 */
declare module '*.jpg' {
  const src: string
  export default src
}

declare module '*.jpeg' {
  const src: string
  export default src
}

declare module '*.png' {
  const src: string
  export default src
}

declare module '*.webp' {
  const src: string
  export default src
}

declare module '*.svg' {
  const src: string
  export default src
}

declare module '*.ttf' {
  const src: string
  export default src
}

rag-frontend\src\main.ts
import { createApp } from 'vue'
import App from './App.vue'
import router from './router'
import store from './store'
// @ts-expect-error: no types for vue3-json-viewer
import JsonViewer from 'vue3-json-viewer'
import 'vue3-json-viewer/dist/index.css' // 引入样式

createApp(App).use(store).use(router).use(JsonViewer).mount('#app')


rag-frontend\src\router\index.ts
import { createRouter, createWebHistory, RouteRecordRaw } from 'vue-router'
import ChatView from '../views/ChatView.vue'
import LoginView from '../views/auth/LoginView.vue'
import RegisterView from '../views/auth/RegisterView.vue'
import AdminRegisterView from '../views/auth/AdminRegisterView.vue'
import AdminView from '../views/admin/AdminView.vue'
import store from '../store'

const routes: Array<RouteRecordRaw> = [
  {
    path: '/',
    name: 'chat',
    component: ChatView,
    meta: { requiresAuth: true }
  },
  {
    path: '/login',
    name: 'login',
    component: LoginView,
    meta: { guestOnly: true }
  },
  {
    path: '/register',
    name: 'register',
    component: RegisterView,
    meta: { guestOnly: true }
  },
  {
    path: '/adminRegister',
    name: 'adminRegister',
    component: AdminRegisterView,
    meta: { guestOnly: true }
  },
  {
    path: '/admin',
    name: 'admin',
    component: AdminView,
    meta: { requiresAuth: true, requiresAdmin: true }
  }
]

const router = createRouter({
  history: createWebHistory(import.meta.env.BASE_URL),
  routes
})

// 全局导航守卫 - 处理路由权限
router.beforeEach(async (to, from, next) => {
  // 验证是否需要登录
  const requiresAuth = to.matched.some(record => record.meta.requiresAuth);
  const guestOnly = to.matched.some(record => record.meta.guestOnly);
  const requiresAdmin = to.matched.some(record => record.meta.requiresAdmin);
  
  // 检查用户是否已登录
  const isAuthenticated = store.getters.isAuthenticated;
  const isAdmin = store.getters.isAdmin;
  
  // 如果是首次访问并且用户已登录 - 尝试获取用户资料
  if (isAuthenticated && !store.state.user) {
    try {
      await store.dispatch('fetchCurrentUser');
    } catch (error) {
      console.error('获取用户信息失败', error);
    }
  }

  // 根据登录状态和路由要求决定导航
  if (requiresAuth && !isAuthenticated) {
    // 需要登录但未登录 - 重定向到登录页
    next({ name: 'login' });
  } else if (guestOnly && isAuthenticated) {
    // 只允许访客但已登录 - 重定向到首页
    next({ name: 'chat' });
  } else if (requiresAdmin && !isAdmin) {
    // 需要管理员权限但不是管理员 - 重定向到首页
    next({ name: 'chat' });
  } else {
    // 其他情况正常导航
    next();
  }
});

export default router

rag-frontend\src\services\admin.ts
import { AxiosResponse } from 'axios';
import httpService from './httpService';

export interface KnowledgeBaseItem {
  title: string;
  content: string;
}

export interface KnowledgeBaseResponse {
  content: KnowledgeBaseItem[];
  page_count: number;
}

export interface UploadKnowledgeBaseResponse {
  success: boolean;
}

/**
 * 分页获取某个知识库的内容
 * @param type 知识库种类
 * @param start_index 起始下标
 * @param page_size 每页大小
 * @returns AxiosResponse<KnowledgeBaseResponse>
 */
export const getKnowledgeBase = async (
  type: 'WIKI' | 'POST' | 'BBS' | 'MODE' | 'ITEM' | 'NEW',
  start_index: number,
  page_size: number
): Promise<AxiosResponse<KnowledgeBaseResponse>> => {
  return await httpService.post<KnowledgeBaseResponse>('/admin/getKnowledgeBase', {
    type,
    start_index,
    page_size
  });
};

/**
 * 上传知识库内容
 * @param dataArr 包含metadata（字符串数组）和file（File）的对象数组
 * @returns AxiosResponse<{success: boolean}>
 */
export const uploadKnowledgeBase = async (
  dataArr: { metadata: string[]; file: File }[]
): Promise<AxiosResponse<UploadKnowledgeBaseResponse>> => {
  const formData = new FormData();
  dataArr.forEach((item, idx) => {
    // metadata作为json字符串上传
    formData.append(`metadata[${idx}]`, JSON.stringify(item.metadata));
    // 文件
    formData.append(`file[${idx}]`, item.file);
  });
  return await httpService.post<UploadKnowledgeBaseResponse>(
    '/admin/uploadKnowledgeBase',
    formData,
    {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    }
  );
};


rag-frontend\src\services\auth.ts
import { AxiosResponse } from 'axios';
import httpService from './httpService';

interface AuthResponse {
  access_token: string;
  token_type: string;
}

interface BasicResponse {
  success: boolean;
  message: string;
}

// 登录
export const login = async (username: string, password: string): Promise<AxiosResponse<AuthResponse>> => {
  return await httpService.post<AuthResponse>('/auth/token', new URLSearchParams({
    username,
    password,
    grant_type: 'password'
  }), {
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded'
    }
  });
};

// 注册
export const register = async (username: string, email: string, password: string): Promise<AxiosResponse<BasicResponse>> => {
  return await httpService.post<BasicResponse>('/auth/register', {
    username,
    email,
    password
  });
};

// 管理员注册
export const adminRegister = async (username: string, email: string, password: string, verification: string): Promise<AxiosResponse<BasicResponse>> => {
  return await httpService.post<BasicResponse>('/auth/adminRegister', {
    username,
    email,
    password,
    verification
  });
};


rag-frontend\src\services\conversation.ts
import { AxiosResponse } from 'axios';
import httpService from './httpService';

interface Message {
  id: number;
  role: string;
  content: string;
  created_at: string;
}

interface Conversation {
  id: number;
  title: string;
  created_at: string;
  updated_at: string;
}

interface ConversationDetail extends Conversation {
  messages: Message[];
}

/**
   * 获取所有对话列表
   * @returns {Promise<AxiosResponse<Conversation[]>>}
   */
export const getConversations = async (): Promise<AxiosResponse<Conversation[]>> => {
  return await httpService.get<Conversation[]>('/conversations');
};

/**
   * 获取单个对话详情
   * @param {number} conversationId - 对话ID
   * @returns {Promise<AxiosResponse<ConversationDetail>>}
   */
export const getConversation = async (conversationId: number): Promise<AxiosResponse<ConversationDetail>> => {
  return await httpService.get<ConversationDetail>(`/conversations/${conversationId}`);
};

/**
   * 更新对话标题
   * @param {number} conversationId - 对话ID
   * @param {string} title - 新标题
   * @returns {Promise<AxiosResponse<Conversation>>}
   */
export const updateConversationTitle = async (conversationId: number, title: string): Promise<AxiosResponse<Conversation>> => {
  return await httpService.put<Conversation>(`/conversations/${conversationId}`, {
    title
  });
};

/**
   * 删除对话
   * @param {number} conversationId - 对话ID
   * @returns {Promise<AxiosResponse<{ message: string }>>}
   */
export const deleteConversation = async (conversationId: number): Promise<AxiosResponse<{ message: string }>> => {
  return await httpService.delete(`/conversations/${conversationId}`);
};


rag-frontend\src\services\conversationSSE.ts
import { fetchEventSource, EventSourceMessage } from '@microsoft/fetch-event-source';

interface ConversationSSECallbacks {
  onOpen?: (response: Response) => void;
  onMessageChunk?: (chunk: string) => void;
  onEnd?: () => void;
  onError?: (msg: string) => void;
  onConversationStart?: (data: { conversation_id: string; title: string }) => void;
  onTitleUpdate?: (title: string) => void;
}

// 新建会话的SSE流
export function startNewConversationSSE({
  message,
  token,
  callbacks
}: {
  message: string;
  token: string;
  callbacks: ConversationSSECallbacks;
}): AbortController {
  const ctrl = new AbortController();
  const headers = {
    'Content-Type': 'application/json',
    'Accept': 'text/event-stream',
    'Authorization': `Bearer ${token}`
  };
  const requestBody = JSON.stringify({ message });
  const endpointUrl = `/api/conversations/new`;

  fetchEventSource(endpointUrl, {
    method: 'POST',
    headers,
    body: requestBody,
    signal: ctrl.signal,
    onopen: async (response) => {
      if (response.ok) {
        console.log('SSE connection opened successfully.');
        callbacks.onOpen?.(response);
      } else {
        const errorText = await response.text();
        console.error(`SSE connection failed: ${response.status} ${response.statusText}`, errorText);
        callbacks.onError?.(`连接错误: ${response.status}`);
        ctrl.abort();
      }
    },
    onmessage: (event: EventSourceMessage) => {
      // console.log("SSE event received:", event.event, event.data); // Debug
      if (event.event === 'end') {
        console.log('SSE stream ended by server "end" event.');
        callbacks.onEnd?.();
        ctrl.abort();
        return;
      }
      if (event.event === 'error') {
        try {
          const errorData = JSON.parse(event.data);
          console.error('Server reported error event:', errorData.message);
          callbacks.onError?.(`抱歉，处理时发生错误：${errorData.message}`);
        } catch (e) {
          console.error('Received unparsable server error event:', event.data);
          callbacks.onError?.('抱歉，处理时发生未知错误。');
        }
        ctrl.abort();
        return;
      }
      switch (event.event) {
        case 'message': {
          const chunk = event.data;
          callbacks.onMessageChunk?.(chunk);
          break;
        }
        case 'conversation_start': {
          try {
            const startData = JSON.parse(event.data);
            callbacks.onConversationStart?.(startData);
            if (startData.conversation_id && startData.title) {
              console.log('已更新会话列表中的标题:', startData.title);
            }
          } catch (e) {
            console.error("Failed to parse conversation_start data:", e);
          }
          break;
        }
        case 'title_update': {
          try {
            const titleData = JSON.parse(event.data);
            callbacks.onTitleUpdate?.(titleData.title);
          } catch (e) {
            console.error("Failed to parse title_update data:", e);
          }
          break;
        }
        default:
          if (event.data) {
            console.warn(`Received unnamed/unknown SSE event, assuming message chunk:`, event.data);
            callbacks.onMessageChunk?.(event.data);
          }
      }
    },
    onclose: () => {
      console.log('SSE connection closed by server or client.');
      callbacks.onEnd?.();
    },
    onerror: (err) => {
      console.error('fetchEventSource encountered an error:', err);
      callbacks.onError?.('网络连接错误或服务器无响应。');
      throw err;
    }
  });
  return ctrl;
}

// 追加消息到已有会话的SSE流
export function addMessageToConversationSSE({
  conversationId,
  message,
  token,
  callbacks
}: {
  conversationId: string;
  message: string;
  token: string;
  callbacks: ConversationSSECallbacks;
}): AbortController {
  const ctrl = new AbortController();
  const headers = {
    'Content-Type': 'application/json',
    'Accept': 'text/event-stream',
    'Authorization': `Bearer ${token}`
  };
  const requestBody = JSON.stringify({ content: message });
  const endpointUrl = `/api/conversations/${conversationId}/messages`;

  fetchEventSource(endpointUrl, {
    method: 'POST',
    headers,
    body: requestBody,
    signal: ctrl.signal,
    onopen: async (response) => {
      if (response.ok) {
        console.log('SSE connection opened successfully.');
        callbacks.onOpen?.(response);
      } else {
        const errorText = await response.text();
        console.error(`SSE connection failed: ${response.status} ${response.statusText}`, errorText);
        callbacks.onError?.(`连接错误: ${response.status}`);
        ctrl.abort();
      }
    },
    onmessage: (event: EventSourceMessage) => {
      // console.log("SSE event received:", event.event, event.data); // Debug
      if (event.event === 'end') {
        console.log('SSE stream ended by server "end" event.');
        callbacks.onEnd?.();
        ctrl.abort();
        return;
      }
      if (event.event === 'error') {
        try {
          const errorData = JSON.parse(event.data);
          console.error('Server reported error event:', errorData.message);
          callbacks.onError?.(`抱歉，处理时发生错误：${errorData.message}`);
        } catch (e) {
          console.error('Received unparsable server error event:', event.data);
          callbacks.onError?.('抱歉，处理时发生未知错误。');
        }
        ctrl.abort();
        return;
      }
      switch (event.event) {
        case 'message': {
          const chunk = event.data;
          callbacks.onMessageChunk?.(chunk);
          break;
        }
        default:
          if (event.data) {
            console.warn(`Received unnamed/unknown SSE event, assuming message chunk:`, event.data);
            callbacks.onMessageChunk?.(event.data);
          }
      }
    },
    onclose: () => {
      console.log('SSE connection closed by server or client.');
      callbacks.onEnd?.();
    },
    onerror: (err) => {
      console.error('fetchEventSource encountered an error:', err);
      callbacks.onError?.('网络连接错误或服务器无响应。');
      throw err;
    }
  });
  return ctrl;
}


rag-frontend\src\services\feedback.ts
import { AxiosResponse } from 'axios';
import httpService from './httpService';

interface FeedbackResponse {
  feedback_id: number;
  success: boolean;
  message: string;
}

/**
   * 提交反馈
   * @param {string} type - 反馈类型
   * @param {string} content - 反馈内容
   * @returns {Promise<AxiosResponse<FeedbackResponse>>}
   */
export const submitFeedback = async (type: string, content: string): Promise<AxiosResponse<FeedbackResponse>> => {
  return await httpService.post<FeedbackResponse>('/feedback', {
    type,
    content
  });
};


rag-frontend\src\services\httpService.ts
import axios, { AxiosInstance } from 'axios';

// 配置API基础URL - 使用Nginx代理
const httpService: AxiosInstance = axios.create({
  baseURL: '/api',  // 使用相对路径，会被Nginx代理转发到后端
  // baseURL: 'http://127.0.0.1:4523/m1/6060246-5750403-default/', // 临时测试
  headers: {
    'Content-Type': 'application/json'
  },
  timeout: 300000  // 5分钟 (300000ms)
});

// 请求拦截器 - 添加token到请求头
httpService.interceptors.request.use(
  (config) => {
    const token = localStorage.getItem('token');
    if (token) {
      config.headers['Authorization'] = `Bearer ${token}`;
    }
    return config;
  },
  (error) => {
    return Promise.reject(error);
  }
);

// 响应拦截器 - 处理401未授权错误
httpService.interceptors.response.use(
  (response) => {
    return response;
  },
  (error) => {
    if (error.response && error.response.status === 401) {
      // 清除token并跳转到登录页
      localStorage.removeItem('token');
      window.location.href = '/login';
    }
    return Promise.reject(error);
  }
);

export default httpService;


rag-frontend\src\services\mock.ts
// 用于mock API响应，现在用不到了
import { AxiosResponse } from 'axios';

// 类型定义
export interface ApiResponse {
  answer: string;
}

export interface MockCategory {
  keywords: string[];
  answers: string[];
}

// 测试用的模拟回答（保留部分示例，便于测试）
export const mockMarkdownResponses: MockCategory[] = [
  {
    keywords: ['合成', '制作', '怎么做', '配方'],
    answers: [
      `# Minecraft 合成指南

## 基础工具合成
要制作**木镐**，你需要以下材料：
- 3个木板
- 2个木棍

### 合成表
将材料按以下方式放置在工作台上：
\`\`\`
[木板] [木板] [木板]
[空]   [木棍] [空]
[空]   [木棍] [空]
\`\`\`

## 高级合成
制作**附魔台**需要：
- 4块黑曜石
- 2颗钻石
- 1本书

![附魔台图片](https://minecraft.fandom.com/wiki/Enchanting_Table)

> 提示：使用钻石镐才能挖掘黑曜石！`
    ]
  },
  {
    keywords: ['怪物', '苦力怕', '僵尸', '骷髅', '敌对'],
    answers: [
      `# Minecraft 敌对生物指南

## 苦力怕 (Creeper)
![Creeper](https://minecraft.fandom.com/wiki/Creeper)

苦力怕是Minecraft中最具标志性的敌对生物。

### 特点
- 无声靠近玩家
- **爆炸**造成环境破坏
- 害怕猫（会远离猫）

### 掉落物
* 0-2 个火药
* 音乐唱片（当被骷髅杀死时）

> 小贴士：制作盾牌可以减少爆炸伤害`
    ]
  }
];

/**
 * 模拟API响应，用于没有后端的测试
 */
export function mockAPIResponse(message: string): Promise<AxiosResponse<ApiResponse>> {
  return new Promise((resolve) => {
    // 减少模拟网络延迟，便于测试 (1-3秒)
    const delay = Math.floor(Math.random() * 2000) + 1000;

    setTimeout(() => {
      const lowercaseMsg = message.toLowerCase();

      // 查找匹配的回答类别
      const matchedCategory = mockMarkdownResponses.find(category =>
        category.keywords.some(keyword => lowercaseMsg.includes(keyword))
      );

      if (matchedCategory) {
        // 从匹配的类别中返回一个随机Markdown回答
        const randomIndex = Math.floor(Math.random() * matchedCategory.answers.length);
        resolve({
          data: {
            answer: matchedCategory.answers[randomIndex]
          },
          status: 200,
          statusText: 'OK',
          headers: {},
          config: {} as any
        });
      } else {
        // 如果没有关键词匹配，返回默认回答
        resolve({
          data: {
            answer: `# 我不太确定这个问题

很抱歉，我对此类问题了解有限。

## 你可以尝试问这些问题：
* 关于**合成配方**的问题
* 关于**怪物**的问题 

或者，你可以查看 [Minecraft Wiki](https://minecraft.fandom.com) 获取更多详细信息！`
          },
          status: 200,
          statusText: 'OK',
          headers: {},
          config: {} as any
        });
      }
    }, delay);
  });
}


rag-frontend\src\services\user.ts
import { AxiosResponse } from 'axios';
import httpService from './httpService';

interface UserResponse {
  user_id: number;
  username: string;
  email: string;
  created_at: string;
  role: 'ADMIN' | 'USER';
}

interface BasicResponse {
  success: boolean;
  message: string;
}

interface QueryItem {
  query_id: number;
  text: string;
  timestamp: string;
  answer: string;
}

interface HistoryResponse {
  queries: QueryItem[];
  total: number;
}

/**
   * 获取当前用户信息
   * @returns {Promise<AxiosResponse<UserResponse>>}
   */
export const getCurrentUser = async (): Promise<AxiosResponse<UserResponse>> => {
  return await httpService.get<UserResponse>('/users/me');
};

/**
   * 更新用户信息（目前在项目中没有用到）
   * @param {Object} updateData - 要更新的数据
   * @returns {Promise<AxiosResponse<BasicResponse>>}
   */
export const updateUserInfo = async (updateData: { username?: string, email?: string, password?: string }): Promise<AxiosResponse<BasicResponse>> => {
  return await httpService.put<BasicResponse>('/users/me', updateData);
};

/**
   * 获取用户历史记录（目前在项目中没有用到）
   * @param {number} limit - 限制条数
   * @param {number} offset - 偏移量
   * @returns {Promise<AxiosResponse<HistoryResponse>>}
   */
export const getUserHistory = async (limit: number = 10, offset: number = 0): Promise<AxiosResponse<HistoryResponse>> => {
  return await httpService.get<HistoryResponse>(`/users/me/history?limit=${limit}&offset=${offset}`);
};


rag-frontend\src\store\index.ts
import { createStore } from 'vuex';
import {
  getConversations,
  getConversation,
  updateConversationTitle,
  deleteConversation
} from '@/services/conversation';
import { login, register, adminRegister } from '@/services/auth';
import { getCurrentUser } from '@/services/user';
import { submitFeedback } from '@/services/feedback';
import type { Message, Conversation, UserData } from '@/types';
import { startNewConversationSSE, addMessageToConversationSSE } from '@/services/conversationSSE';

export default createStore({
  state: {
    token: localStorage.getItem('token'),
    user: null as UserData | null,
    isAuthenticated: !!localStorage.getItem('token'),
    error: null,
    loading: false,
    conversations: [] as Conversation[],
    currentConversation: null as Conversation | null,
    loadingConversations: false,
    loadingMessages: false,
    feedbackSubmitting: false, // 添加反馈提交状态
    currentAbortController: null as AbortController | null, // 用于取消流式传输
    isAdmin: localStorage.getItem('role') === 'ADMIN' // 由role判断
  },
  getters: {
    isAuthenticated: (state) => state.isAuthenticated,
    currentUser: (state) => state.user,
    authError: (state) => state.error,
    allConversations: (state) => state.conversations,
    currentConversation: (state) => state.currentConversation,
    isAdmin: (state) => state.isAdmin // getter不变
  },
  mutations: {
    setToken(state, token) {
      state.token = token;
      state.isAuthenticated = !!token;
      if (token) {
        localStorage.setItem('token', token);
      } else {
        localStorage.removeItem('token');
      }
    },
    setUser(state, user) {
      state.user = user;
      // 新增：同步 isAdmin
      const isAdmin = user && (user.role === 'ADMIN');
      state.isAdmin = isAdmin;
      localStorage.setItem('role', user?.role || ''); // 存储role
    },
    setError(state, error) {
      state.error = error;
    },
    setLoading(state, status) {
      state.loading = status;
    },
    clearAuthState(state) {
      state.token = null;
      state.user = null;
      state.isAuthenticated = false;
      state.isAdmin = false; // 新增
      localStorage.removeItem('token');
      localStorage.removeItem('role'); // 移除role
    },
    setConversations(state, conversations) {
      state.conversations = conversations;
    },
    setCurrentConversation(state, conversation) {
      // 检查当前会话是否有正在加载的消息
      const isLoading = !!state.currentConversation?.messages?.find(m => m.isLoading);

      if (isLoading && state.currentConversation) {
        console.log('当前有消息正在生成，保留当前会话状态');
        return; // 如果有消息正在生成，不更新当前会话
      }

      // 如果是同一个会话，合并消息而不是替换
      if (state.currentConversation && conversation && state.currentConversation.id === conversation.id) {
        // 保留当前会话的其他属性，只更新消息
        if (conversation.messages) {
          state.currentConversation.messages = conversation.messages;
        }
        console.log('更新了同一会话的消息');
      } else {
        // 完全替换当前会话
        state.currentConversation = conversation;
        console.log('设置了新的当前会话:', conversation?.id);
      }
    },
    addConversation(state, conversation) {
      state.conversations.unshift(conversation); // 添加到队列前面
    },
    updateConversation(state, { id, title }) {
      const index = state.conversations.findIndex(c => c.id === id);
      if (index !== -1) {
        state.conversations[index].title = title;
        if (state.currentConversation && state.currentConversation.id === id) {
          state.currentConversation.title = title;
        }
      }
    },

    // 更新会话列表中的会话信息
    updateConversationInList(state, { id, title }) {
      // 查找会话在列表中的索引
      const index = state.conversations.findIndex(c => c.id === id);

      if (index !== -1) {
        // 如果找到了会话，更新它的标题
        state.conversations[index].title = title;
        // 更新时间戳
        state.conversations[index].updated_at = new Date().toISOString();

        // 如果这个会话不在列表的第一位，将它移到第一位
        if (index > 0) {
          // 移除会话
          const conversation = state.conversations.splice(index, 1)[0];
          // 添加到列表开头
          state.conversations.unshift(conversation);
        }

        // 同时更新当前会话的标题（如果是当前会话）
        if (state.currentConversation && state.currentConversation.id === id) {
          state.currentConversation.title = title;
        }
      } else {
        // 如果会话不在列表中，可能需要添加它
        // 但通常这种情况不会发生，因为会话应该已经在列表中
        console.log('会话不在列表中，无法更新标题:', id);
      }
    },
    deleteConversationById(state, id) {
      state.conversations = state.conversations.filter(c => c.id !== id);
      if (state.currentConversation && state.currentConversation.id === id) {
        state.currentConversation = null;
      }
    },
    addMessagesToConversation(state, { conversationId, messages }) {
      if (state.currentConversation && state.currentConversation.id === conversationId) {
        if (!state.currentConversation.messages) {
          state.currentConversation.messages = [];
        }

        // Clone the existing messages to create a new array reference
        const updatedMessages = [...state.currentConversation.messages];
        updatedMessages.push(...messages);

        // Replace the entire messages array with the new one
        state.currentConversation.messages = updatedMessages;
      }
    },
    setLoadingConversations(state, status) {
      state.loadingConversations = status;
    },
    setLoadingMessages(state, status) {
      state.loadingMessages = status;
    },
    setFeedbackSubmitting(state, status) {
      state.feedbackSubmitting = status;
    },
    clearConversations(state) {
      state.conversations = [];
      state.currentConversation = null;
    },
    // 新增：设置当前的 AbortController
    setCurrentAbortController(state, controller) {
      state.currentAbortController = controller;
    },
    // 新增：向消息追加内容块
    appendMessageChunk(state, { messageId, chunk }) {
      if (state.currentConversation && state.currentConversation.messages) {
        const message = state.currentConversation.messages.find(m => m.id === messageId);
        if (message) {
          // 创建新的内容，确保响应式更新
          if (chunk) {
            message.content = (message.content || '') + chunk;
          } else {
            message.content = (message.content || '') + '\n';
          }
        }
      }
    },
    // 新增：完成助手消息（停止加载状态）
    finalizeAssistantMessage(state, { messageId, error = false, content = null }) {
      if (state.currentConversation && state.currentConversation.messages) {
        const message = state.currentConversation.messages.find(m => m.id === messageId);
        if (message) {
          message.isLoading = false;
          message.isError = error;
          if (content !== null) {
            message.content = content;
          }
        }
      }
    },
    // setConversationSources mutation 已移除
    // 更新新对话的详细信息（从临时ID转换为真实ID）
    updateNewConversationDetails(state, { tempId, conversation_id, title }) {
      // 更新当前对话
      if (state.currentConversation) {
        // 保存当前对话的消息和其他属性
        const currentMessages = state.currentConversation.messages || [];

        // 查找临时ID在会话列表中的索引
        const tempIndex = state.conversations.findIndex(c =>
          String(c.id).startsWith('temp_')
        );

        // 如果找到了临时ID的会话，从列表中移除它
        if (tempIndex !== -1) {
          state.conversations.splice(tempIndex, 1);
        }

        // 更新当前会话的ID和标题
        state.currentConversation.id = conversation_id;
        state.currentConversation.title = title;

        // 检查真实ID是否已存在于会话列表中
        const existingIndex = state.conversations.findIndex(c => c.id === conversation_id);

        if (existingIndex === -1) {
          // 如果会话列表中没有这个真实ID的会话，添加它
          state.conversations.unshift({
            id: conversation_id,
            title: title,
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString(),
            messages: currentMessages // 保留消息
          });
        } else {
          // 如果已存在，更新它的标题和消息
          state.conversations[existingIndex].title = title;
          state.conversations[existingIndex].messages = currentMessages;
        }

        console.log(`对话ID已更新: 临时ID -> ${conversation_id}`);
      }
    }
  },
  actions: {
    async login({ commit, dispatch }, { username, password }) {
      try {
        commit('setLoading', true);
        commit('setError', null);
        const response = await login(username, password);
        const token = response.data.access_token;
        commit('setToken', token);
        await dispatch('fetchCurrentUser');
        return true;
      } catch (error: any) {
        let errorMsg = '登录失败';
        if (error.response) {
          errorMsg = error.response.data.detail || '用户名或密码错误';
        }
        commit('setError', errorMsg);
        return false;
      } finally {
        commit('setLoading', false);
        console.log('用户身份:', localStorage.getItem('role'));
      }
    },
    async register({ commit }, { username, email, password }) {
      try {
        commit('setLoading', true);
        commit('setError', null);
        await register(username, email, password);
        return true;
      } catch (error: any) {
        let errorMsg = '注册失败';
        if (error.response) {
          errorMsg = error.response.data.detail || '注册信息有误';
        }
        commit('setError', errorMsg);
        return false;
      } finally {
        commit('setLoading', false);
      }
    },
    async adminRegister({ commit }, { username, email, password, verification }) {
      try {
        commit('setLoading', true);
        commit('setError', null);
        await adminRegister(username, email, password, verification);
        return true;
      } catch (error: any) {
        let errorMsg = '注册失败';
        if (error.response) {
          errorMsg = error.response.data.detail || '注册信息有误';
        }
        commit('setError', errorMsg);
        return false;
      } finally {
        commit('setLoading', false);
      }
    },
    async fetchCurrentUser({ commit }) {
      try {
        commit('setLoading', true);
        const response = await getCurrentUser();
        commit('setUser', response.data);
        return response.data;
      } catch (error) {
        commit('clearAuthState');
        return null;
      } finally {
        commit('setLoading', false);
      }
    },
    logout({ commit }) {
      commit('clearAuthState');
      commit('clearConversations');
    },

    // 会话相关的actions
    async fetchConversations({ commit }) {
      try {
        commit('setLoadingConversations', true);
        const response = await getConversations();
        commit('setConversations', response.data);
        return response.data;
      } catch (error) {
        console.error('获取会话列表失败:', error);
        return [];
      } finally {
        commit('setLoadingConversations', false);
      }
    },
    async fetchConversationDetail({ commit, state }, conversationId) {
      try {
        // 检查当前会话是否有正在加载的消息
        const isLoading = !!state.currentConversation?.messages?.find(m => m.isLoading);
        if (isLoading) {
          console.log('跳过获取会话详情，因为当前有消息正在生成:', conversationId);
          return state.currentConversation;
        }

        // 检查是否已经是当前会话
        if (state.currentConversation?.id === conversationId) {
          console.log('当前会话已经是请求的会话，跳过重复加载:', conversationId);
          return state.currentConversation;
        }

        console.log('获取会话详情:', conversationId);
        commit('setLoadingMessages', true);
        const response = await getConversation(conversationId);

        // 设置新的会话
        commit('setCurrentConversation', response.data);

        return response.data;
      } catch (error) {
        console.error('获取会话详情失败:', error);
        return null;
      } finally {
        commit('setLoadingMessages', false);
      }
    },
    async createNewConversation({ commit, state }, message) {
      // 1. 取消之前的请求 (如果存在)
      if (state.currentAbortController) {
        state.currentAbortController.abort();
        commit('setCurrentAbortController', null); // 清理控制器
      }

      try {
        commit('setLoadingMessages', true);

        // 2. 创建临时会话对象
        const tempConversationId = `temp_${Date.now()}`;

        // 3. 添加用户消息
        const userMessage = {
          id: Date.now(),
          role: 'user',
          content: message,
          created_at: new Date().toISOString(),
          sender: 'user',
          text: message,
          timestamp: new Date()
        };

        // 4. 添加助手占位符消息
        const tempAssistantId = `temp_${Date.now() + 1}`;
        const assistantPlaceholder = {
          id: tempAssistantId,
          role: 'assistant',
          content: '',
          created_at: new Date().toISOString(),
          sender: 'assistant',
          text: '',
          timestamp: new Date(),
          isLoading: true,
          isError: false
        };

        // 5. 创建临时会话
        const tempConversation: Conversation = {
          id: tempConversationId as any, // 临时ID，将被后端返回的真实ID替换
          title: '新对话',
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString(),
          messages: [userMessage as Message, assistantPlaceholder as Message]
        };

        // 6. 添加临时会话到状态
        commit('addConversation', tempConversation);
        commit('setCurrentConversation', tempConversation);

        // 7. 使用service封装的SSE请求
        const ctrl = startNewConversationSSE({
          message,
          token: state.token as string,
          callbacks: {
            onOpen: () => {},
            onMessageChunk: (chunk) => {
              commit('appendMessageChunk', { messageId: tempAssistantId, chunk });
            },
            onEnd: () => {
              commit('finalizeAssistantMessage', { messageId: tempAssistantId });
              commit('setCurrentAbortController', null);
            },
            onError: (msg) => {
              commit('finalizeAssistantMessage', {
                messageId: tempAssistantId,
                error: true,
                content: msg
              });
              commit('setCurrentAbortController', null);
            },
            onConversationStart: (startData) => {
              commit('updateNewConversationDetails', {
                tempId: tempAssistantId,
                conversation_id: startData.conversation_id,
                title: startData.title || '新对话'
              });
              if (startData.conversation_id && startData.title) {
                commit('updateConversationInList', {
                  id: startData.conversation_id,
                  title: startData.title
                });
                console.log('已更新会话列表中的标题:', startData.title);
              }
            },
            onTitleUpdate: (title) => {
              if (state.currentConversation) {
                commit('updateConversation', {
                  id: state.currentConversation.id,
                  title
                });
              }
            }
          }
        });
        commit('setCurrentAbortController', ctrl); // 保存控制器以备取消
        return state.currentConversation;
      } catch (error) {
        console.error('创建新会话失败:', error);
        return null;
      } finally {
        commit('setLoadingMessages', false);
      }
    },
    async addMessageToConversation({ commit, state }, { conversationId, message }) {
      // 1. 取消之前的请求 (如果存在)
      if (state.currentAbortController) {
        state.currentAbortController.abort();
        commit('setCurrentAbortController', null); // 清理控制器
      }

      try {
        commit('setLoadingMessages', true);

        // 2. 添加用户消息
        const userMessage = {
          id: Date.now(),
          role: 'user',
          content: message,
          created_at: new Date().toISOString(),
          sender: 'user',
          text: message,
          timestamp: new Date()
        };

        commit('addMessagesToConversation', {
          conversationId,
          messages: [userMessage]
        });

        // 3. 添加助手占位符消息
        const tempAssistantId = `temp_${Date.now()}`;
        const assistantPlaceholder = {
          id: tempAssistantId,
          role: 'assistant',
          content: '',
          created_at: new Date().toISOString(),
          sender: 'assistant',
          text: '',
          timestamp: new Date(),
          isLoading: true,
          isError: false
        };

        commit('addMessagesToConversation', {
          conversationId,
          messages: [assistantPlaceholder]
        });

        // 4. 使用service封装的SSE请求
        const ctrl = addMessageToConversationSSE({
          conversationId,
          message,
          token: state.token as string,
          callbacks: {
            onOpen: () => {},
            onMessageChunk: (chunk) => {
              commit('appendMessageChunk', { messageId: tempAssistantId, chunk });
            },
            onEnd: () => {
              commit('finalizeAssistantMessage', { messageId: tempAssistantId });
              commit('setCurrentAbortController', null);
            },
            onError: (msg) => {
              commit('finalizeAssistantMessage', {
                messageId: tempAssistantId,
                error: true,
                content: msg
              });
              commit('setCurrentAbortController', null);
            }
          }
        });
        commit('setCurrentAbortController', ctrl); // 保存控制器以备取消

        // 更新会话列表中对应会话的更新时间
        const conversationIndex = state.conversations.findIndex(c => c.id === conversationId);
        if (conversationIndex !== -1) {
          const updatedConversation = { ...state.conversations[conversationIndex] };
          updatedConversation.updated_at = new Date().toISOString();

          // 移除旧的会话
          const newConversations = state.conversations.filter(c => c.id !== conversationId);
          // 将更新后的会话添加到最前面
          newConversations.unshift(updatedConversation);
          commit('setConversations', newConversations);
        }

        return true;
      } catch (error) {
        console.error('发送消息失败:', error);
        return false;
      } finally {
        commit('setLoadingMessages', false);
      }
    },
    async updateConversationTitle({ commit }, { conversationId, title }) {
      try {
        const response = await updateConversationTitle(conversationId, title);
        commit('updateConversation', { id: conversationId, title });
        return response.data;
      } catch (error) {
        console.error('更新会话标题失败:', error);
        return null;
      }
    },
    async deleteConversation({ commit }, conversationId) {
      try {
        await deleteConversation(conversationId);
        commit('deleteConversationById', conversationId);
        return true;
      } catch (error) {
        console.error('删除会话失败:', error);
        return false;
      }
    },
    async submitFeedback({ commit }, { type, content }) {
      try {
        commit('setFeedbackSubmitting', true);
        commit('setError', null);
        const response = await submitFeedback(type, content);
        return true;
      } catch (error: any) {
        let errorMsg = '提交反馈失败';
        if (error.response) {
          errorMsg = error.response.data.detail || '提交失败，请稍后再试';
        }
        commit('setError', errorMsg);
        return false;
      } finally {
        commit('setFeedbackSubmitting', false);
      }
    },

    // 新增：取消流式传输
    cancelStream({ state, commit }) {
      if (state.currentAbortController) {
        console.log("用户请求取消流...");
        state.currentAbortController.abort();

        // 查找正在加载的消息并标记为已取消
        if (state.currentConversation && state.currentConversation.messages) {
          const loadingMessage = state.currentConversation.messages.find(m => m.isLoading);
          if (loadingMessage) {
            commit('finalizeAssistantMessage', {
              messageId: loadingMessage.id,
              content: (loadingMessage.content || "") + " (已停止)"
            });
          }
        }

        commit('setCurrentAbortController', null);
      }
    }
  }
});


rag-frontend\src\types\index.ts
export interface Message {
  id?: number | string;
  text?: string;
  sender?: 'user' | 'assistant';
  timestamp?: Date;
  html?: string;
  role?: string;
  content?: string;
  created_at?: string;
  isLoading?: boolean;
  isError?: boolean;
}

export interface Conversation {
  id: number;
  title: string;
  created_at: string;
  updated_at: string;
  messages?: Message[];
}

export interface UserState {
  token: string | null;
  user: {
    user_id?: number;
    username?: string;
    email?: string;
    created_at?: string;
  } | null;
  isAuthenticated: boolean;
  error: string | null;
  loading: boolean;
  conversations: Conversation[];
  currentConversation: Conversation | null;
  loadingConversations: boolean;
  loadingMessages: boolean;
  feedbackSubmitting: boolean;
  currentAbortController: AbortController | null;
}

export interface UserData {
  user_id?: number;
  username?: string;
  email?: string;
  created_at?: string;
  role?: 'ADMIN' | 'USER';
}






【当前RAG应用后端完整代码】
rag\src\rag\config.py
# src/rag/config.py
import os
from dotenv import load_dotenv
from pathlib import Path
import logging

# --- 初始化日志记录器 (用于配置加载过程的日志) ---
# 注意: 这个基础日志配置应与项目中统一的 logging_config.py 协调，
# 避免冲突或重复配置。这里仅为展示配置加载时的日志输出。
logging.basicConfig(
    level=os.getenv("LOG_LEVEL", "INFO").upper(), # 尝试从环境变量预读日志级别
    format='%(asctime)s - %(name)s.%(funcName)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("rag.config") # 使用带层级的 logger 名称

# --- 确定 .env 文件路径 ---
# 假设 config.py 位于 src/rag/config.py
# 项目根目录通常是 src/ 目录的父目录
try:
    current_file_path = Path(__file__).resolve()
    project_root_from_config = current_file_path.parent.parent.parent
    default_env_path = project_root_from_config / ".env"
except NameError: # __file__ 未定义 (例如在某些交互式环境中)
    default_env_path = Path(os.getcwd()) / ".env"


# 允许通过环境变量指定 .env 文件位置，增加灵活性
ENV_FILE_PATH_OVERRIDE = os.getenv("RAG_ENV_FILE_PATH")

env_path_to_load = None
if ENV_FILE_PATH_OVERRIDE and Path(ENV_FILE_PATH_OVERRIDE).exists():
    env_path_to_load = Path(ENV_FILE_PATH_OVERRIDE)
    logger.info(f"尝试从 RAG_ENV_FILE_PATH 加载 .env 文件: {env_path_to_load}")
elif default_env_path.exists():
    env_path_to_load = default_env_path
    logger.info(f"尝试从默认位置加载 .env 文件: {env_path_to_load}")
else:
    # 尝试当前工作目录作为最后的备选
    cwd_env_path = Path(os.getcwd()) / ".env"
    if cwd_env_path.exists():
        env_path_to_load = cwd_env_path
        logger.info(f"尝试从当前工作目录加载 .env 文件: {env_path_to_load}")
    else:
        logger.warning(
            f"在指定的 RAG_ENV_FILE_PATH、"
            f"默认位置 ({default_env_path}) "
            f"或当前工作目录 ({cwd_env_path}) "
            f"均未找到 .env 文件。"
            "将依赖现有的环境变量和代码默认值。"
        )

# --- 加载 .env 文件 (如果找到) ---
if env_path_to_load:
    load_dotenv(dotenv_path=env_path_to_load, override=True)
    logger.info(f"成功从以下路径加载配置: {env_path_to_load}")
else:
    # 即使没找到 .env 文件，也调用一次 load_dotenv()
    # 这样如果环境变量已经由外部设置（如 Docker, K8s），它们仍然会被 os.getenv 读取
    load_dotenv(override=True)
    logger.info("未通过路径加载 .env 文件，将依赖预先存在的环境变量或默认值。")

# --- 辅助函数：获取环境变量，进行类型转换，并提供默认值 ---
# 特殊类型标记，用于 get_env_var 的 var_type 参数
class ListStrMarker: pass # 用于逗号分隔的字符串列表
class BoolMarker: pass   # 用于更明确的布尔转换

def get_env_var(var_name: str, default_value=None, var_type=str):
    """
    检索环境变量，如果未找到则提供默认值，
    并执行类型转换。
    """
    raw_value = os.getenv(var_name)

    if raw_value is None: # 环境变量未设置
        if default_value is None and not (var_type is str or var_type is ListStrMarker or isinstance(var_type, type(None))):
             # 仅对非字符串、非列表且非可选类型，且没有默认值的情况发出警告或错误
             # logger.warning(f"Configuration variable '{var_name}' is not set and has no default, but type is {var_type}.")
             pass # 允许为None，由使用者处理
        value_to_convert = default_value
    else:
        value_to_convert = raw_value

    if value_to_convert is None: # 无论来源，如果最终值是None，直接返回
        return None

    try:
        if var_type is BoolMarker:
            if isinstance(value_to_convert, bool): return value_to_convert
            return str(value_to_convert).lower() in ('true', '1', 't', 'yes', 'y')
        elif var_type is int:
            return int(value_to_convert)
        elif var_type is float:
            return float(value_to_convert)
        elif var_type is ListStrMarker: # 逗号分隔的字符串列表
            if isinstance(value_to_convert, list): return value_to_convert # 如果默认值已经是列表
            return [item.strip() for item in str(value_to_convert).split(',') if item.strip()]
        elif var_type is str:
            return str(value_to_convert)
        else: # 如果 var_type 是其他 callable (如 Path)
            return var_type(value_to_convert)
    except (ValueError, TypeError) as e:
        logger.error(
            f"转换环境变量 '{var_name}' "
            f"的值 '{value_to_convert}' (类型: {type(value_to_convert).__name__}) "
            f"到类型 {var_type.__name__ if hasattr(var_type, '__name__') else str(var_type)} 时出错。"
            f"使用默认值: '{default_value}'。错误: {e}"
        )
        return default_value


# --- 定义所有配置变量 ---

# LLM Configurations
# 通用 (默认，如果未配置特定任务的 LLM，则作为后备)
LLM_MODEL = get_env_var("LLM_MODEL", "THUDM/GLM-Z1-32B-0414")
BASE_URL = get_env_var("BASE_URL", "https://api.siliconflow.cn/v1")
API_KEY = get_env_var("API_KEY", None) # API 密钥理想情况下不应有硬编码的默认值

# RAG System LLM
RAG_LLM_MODEL = get_env_var("RAG_LLM_MODEL", LLM_MODEL)
RAG_BASE_URL = get_env_var("RAG_BASE_URL", BASE_URL)
RAG_API_KEY = get_env_var("RAG_API_KEY", API_KEY)
RAG_TEMPERATURE = get_env_var("RAG_TEMPERATURE", 0.1, float)

# Title Generation LLM
TITLE_LLM_MODEL = get_env_var("TITLE_LLM_MODEL", "THUDM/GLM-4-9B-0414")
TITLE_BASE_URL = get_env_var("TITLE_BASE_URL", BASE_URL)
TITLE_API_KEY = get_env_var("TITLE_API_KEY", API_KEY)
TITLE_TEMPERATURE = get_env_var("TITLE_TEMPERATURE", 0.3, float)

# Metadata Matching LLM
METADATA_LLM_MODEL = get_env_var("METADATA_LLM_MODEL", "THUDM/GLM-4-9B-0414")
METADATA_BASE_URL = get_env_var("METADATA_BASE_URL", BASE_URL)
METADATA_API_KEY = get_env_var("METADATA_API_KEY", API_KEY)
METADATA_TEMPERATURE = get_env_var("METADATA_TEMPERATURE", 0.0, float)

# Intent Classification LLM
INTENT_LLM_MODEL = get_env_var("INTENT_LLM_MODEL", "THUDM/GLM-4-9B-0414")
INTENT_BASE_URL = get_env_var("INTENT_BASE_URL", BASE_URL)
INTENT_API_KEY = get_env_var("INTENT_API_KEY", API_KEY)
INTENT_TEMPERATURE = get_env_var("INTENT_TEMPERATURE", 0.0, float)

# Embedding and Vector Database
BAAI_PATH = get_env_var("BAAI_PATH", "BAAI/bge-large-zh-v1.5") # 可以是 HuggingFace Hub 名称或本地路径
CHROMA_PATH = get_env_var("CHROMA_PATH", "./default_chroma_db_location") # 代码级别的默认值
DEVICE = get_env_var("DEVICE", "cpu") # 应为 "cpu" 或 "cuda"

# Running Environment
ENVIRONMENT = get_env_var("ENVIRONMENT", "development") # 例如 "development", "production"

# Database (MySQL)
DATABASE_URL = get_env_var("DATABASE_URL", "mysql+pymysql://root:123456@localhost/rag_db_default")

# JWT Authentication
SECRET_KEY = get_env_var("SECRET_KEY", "change-this-default-secret-key-in-production") # 关键: 在生产环境的 .env 文件中覆盖此值
ACCESS_TOKEN_EXPIRE_MINUTES = get_env_var("ACCESS_TOKEN_EXPIRE_MINUTES", 60 * 24 * 7, int) # 默认: 1 周

# 检索超参数 (代码级别默认值，可通过 .env 文件覆盖)
RETRIEVER_INITIAL_K = get_env_var("RETRIEVER_INITIAL_K", 15, int)
RERANK_MODEL_NAME = get_env_var("RERANK_MODEL_NAME", "BAAI/bge-reranker-v2-m3") # HuggingFace Hub 名称或本地路径
RERANK_TOP_K = get_env_var("RERANK_TOP_K", 5, int)
RERANK_BATCH_SIZE = get_env_var("RERANK_BATCH_SIZE", 8, int) # 重排序批处理大小，CPU环境下建议较小值

# 查询扩展配置
QUERY_EXPANSION_ENABLED = get_env_var("QUERY_EXPANSION_ENABLED", True, BoolMarker)
QUERY_EXPANSION_TEMPERATURE = get_env_var("QUERY_EXPANSION_TEMPERATURE", 0.2, float)
QUERY_EXPANSION_LLM_MODEL = get_env_var("QUERY_EXPANSION_LLM_MODEL", "THUDM/GLM-4-9B-0414")
QUERY_EXPANSION_BASE_URL = get_env_var("QUERY_EXPANSION_BASE_URL", BASE_URL)
QUERY_EXPANSION_API_KEY = get_env_var("QUERY_EXPANSION_API_KEY", API_KEY)

# Application Specific Settings
LOG_LEVEL = get_env_var("LOG_LEVEL", "INFO").upper()
# 本地开发的默认CORS配置。对于其他环境，请在 .env 文件中覆盖。
CORS_ALLOWED_ORIGINS = get_env_var("CORS_ALLOWED_ORIGINS", "http://localhost:8080,http://127.0.0.1:8080", ListStrMarker)


# --- (可选) 记录生效的配置以供调试 ---
# 这最好在主日志系统完全配置后完成
def log_effective_configuration():
    # 如果 LOG_LEVEL 已通过 .env 更新，则重新获取 logger 实例
    effective_logger = logging.getLogger("rag.config.effective")
    if effective_logger.isEnabledFor(logging.INFO): # 检查是否启用了 INFO 级别
        effective_logger.info("--- 生效配置摘要 ---")
        # 选择性地记录非敏感或摘要性配置
        config_summary = {
            "ENVIRONMENT": ENVIRONMENT,
            "LOG_LEVEL": LOG_LEVEL,
            "LLM_MODEL (Default)": LLM_MODEL,
            "RAG_LLM_MODEL": RAG_LLM_MODEL,
            "DATABASE_URL (Host/DB)": DATABASE_URL.split('@')[-1] if '@' in DATABASE_URL else DATABASE_URL,
            "BAAI_PATH": BAAI_PATH,
            "CHROMA_PATH": CHROMA_PATH,
            "DEVICE": DEVICE,
            "RETRIEVER_INITIAL_K": RETRIEVER_INITIAL_K,
            "RERANK_MODEL_NAME": RERANK_MODEL_NAME,
            "RERANK_TOP_K": RERANK_TOP_K,
            "QUERY_EXPANSION_ENABLED": QUERY_EXPANSION_ENABLED,
            "QUERY_EXPANSION_TEMPERATURE": QUERY_EXPANSION_TEMPERATURE,
            "QUERY_EXPANSION_LLM_MODEL": QUERY_EXPANSION_LLM_MODEL,
            "API_KEY_IS_SET": "Yes" if API_KEY else "No",
            "SECRET_KEY_IS_DEFAULT": "Yes" if SECRET_KEY == "change-this-default-secret-key-in-production" else "No (Custom)",
            "CORS_ALLOWED_ORIGINS": CORS_ALLOWED_ORIGINS,
        }
        for key, value in config_summary.items():
            effective_logger.info(f"{key}: {value}")
        effective_logger.info("--- 生效配置摘要结束 ---")


rag\src\rag\database.py
"""
数据库模型和会话管理模块

此模块定义了项目使用的 SQLAlchemy 数据库模型，
以及用于创建数据库表和管理数据库会话的函数。
"""
from sqlalchemy import create_engine, Column, Integer, String, DateTime, ForeignKey, Text, Boolean, Enum
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship
from sqlalchemy.sql import func
from . import config
# 移除未使用的导入
# from datetime import datetime
import enum

# 数据库配置

# 创建数据库引擎
engine = create_engine(config.DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# 创建Base类
Base = declarative_base()

# 反馈类型枚举
class FeedbackType(str, enum.Enum):
    BUG = "bug"
    FEATURE = "feature"
    CONTENT = "content"
    OTHER = "other"

# 反馈状态枚举
class FeedbackStatus(str, enum.Enum):
    PENDING = "pending"
    REVIEWED = "reviewed"
    IMPLEMENTED = "implemented"
    REJECTED = "rejected"

# 用户模型
class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String(50), unique=True, index=True)
    email = Column(String(100), unique=True, index=True)
    hashed_password = Column(String(100))
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    is_active = Column(Boolean, default=True, index=True)

    # 关系
    queries = relationship("Query", back_populates="user")
    conversations = relationship("Conversation", back_populates="user")
    feedbacks = relationship("Feedback", back_populates="user")

# 查询历史模型
class Query(Base):
    __tablename__ = "queries"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), index=True)
    text = Column(Text)
    answer = Column(Text)
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)

    # 关系
    user = relationship("User", back_populates="queries")

# 对话模型
class Conversation(Base):
    __tablename__ = "conversations"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), index=True)
    title = Column(String(255))
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), index=True)

    # 关系
    user = relationship("User", back_populates="conversations")
    messages = relationship("Message", back_populates="conversation", cascade="all, delete-orphan")

# 消息模型
class Message(Base):
    __tablename__ = "messages"

    id = Column(Integer, primary_key=True, index=True)
    conversation_id = Column(Integer, ForeignKey("conversations.id"), index=True)
    role = Column(String(20))  # 'user' 或 'assistant'
    content = Column(Text)
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)

    # 关系
    conversation = relationship("Conversation", back_populates="messages")

# 反馈模型
class Feedback(Base):
    __tablename__ = "feedbacks"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), index=True)
    type = Column(Enum(FeedbackType), nullable=False)
    content = Column(Text, nullable=False)
    status = Column(Enum(FeedbackStatus), default=FeedbackStatus.PENDING, index=True)
    admin_response = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), index=True)

    # 关系
    user = relationship("User", back_populates="feedbacks")



# 初始化数据库
def init_db():
    Base.metadata.create_all(bind=engine)

# 获取数据库会话
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

rag\src\rag\dependencies.py
"""
依赖注入模块

此模块提供FastAPI依赖注入函数，用于创建和提供应用程序所需的各种组件实例。
这些函数使用FastAPI的Depends机制，实现了组件的懒加载和依赖关系管理。
"""

from functools import lru_cache
from fastapi import Depends, Request, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session
from langchain_openai import ChatOpenAI
from langchain.retrievers import EnsembleRetriever
from langchain_community.document_transformers import EmbeddingsRedundantFilter
from langchain_core.prompts import ChatPromptTemplate

from .database import get_db, User
from .services.conversation_service import ConversationService
from .services.feedback_service import FeedbackService
from .services.auth_service import AuthService
from .rag_pipeline.pipeline import RAGPipeline
from .rag_pipeline.intent_processing import IntentClassifier

# OAuth2密码Bearer令牌
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/token")


def get_rag_llm(request: Request) -> ChatOpenAI:
    """
    获取RAG系统使用的LLM客户端

    Args:
        request: FastAPI请求对象，用于访问应用状态

    Returns:
        ChatOpenAI: RAG系统使用的LLM客户端实例
    """
    return request.app.state.llm["rag"]


def get_title_llm(request: Request) -> ChatOpenAI:
    """
    获取标题生成使用的LLM客户端

    Args:
        request: FastAPI请求对象，用于访问应用状态

    Returns:
        ChatOpenAI: 标题生成使用的LLM客户端实例
    """
    return request.app.state.llm["title"]


# 移除了 get_ensemble_retriever 函数，因为它依赖的 app.state.ensemble 已不再使用。

def get_redundant_filter(request: Request) -> EmbeddingsRedundantFilter:
    """
    获取冗余过滤器

    Args:
        request: FastAPI请求对象，用于访问应用状态

    Returns:
        EmbeddingsRedundantFilter: 冗余过滤器实例
    """
    return request.app.state.filter


def get_rag_prompt(request: Request) -> ChatPromptTemplate:
    """
    获取RAG提示模板

    Args:
        request: FastAPI请求对象，用于访问应用状态

    Returns:
        ChatPromptTemplate: RAG提示模板实例
    """
    return request.app.state.prompt


def get_intent_classifier(request: Request) -> IntentClassifier:
    """
    获取意图分类器

    Args:
        request: FastAPI请求对象，用于访问应用状态

    Returns:
        IntentClassifier: 意图分类器实例
    """
    return request.app.state.intent_classifier


def get_rag_pipeline(request: Request) -> RAGPipeline:
    """
    获取RAG Pipeline

    Args:
        request: FastAPI请求对象，用于访问应用状态

    Returns:
        RAGPipeline: RAG Pipeline实例
    """
    return request.app.state.rag_pipeline


def get_conversation_service(
    db: Session = Depends(get_db),
    rag_pipeline: RAGPipeline = Depends(get_rag_pipeline),
) -> ConversationService:
    """
    创建并提供ConversationService实例

    Args:
        db: 数据库会话
        rag_pipeline: RAG Pipeline实例

    Returns:
        ConversationService: 对话服务实例
    """
    return ConversationService(
        db=db,
        rag_pipeline=rag_pipeline,
    )


def get_feedback_service(
    db: Session = Depends(get_db),
) -> FeedbackService:
    """
    创建并提供FeedbackService实例

    Args:
        db: 数据库会话

    Returns:
        FeedbackService: 反馈服务实例
    """
    return FeedbackService(db=db)


def get_auth_service(
    db: Session = Depends(get_db),
) -> AuthService:
    """
    创建并提供AuthService实例

    Args:
        db: 数据库会话

    Returns:
        AuthService: 认证服务实例
    """
    return AuthService(db=db)


# 验证当前用户的依赖项
async def get_current_user(
    token: str = Depends(oauth2_scheme),
    auth_service: AuthService = Depends(get_auth_service)
) -> User:
    """
    验证当前用户的依赖函数

    Args:
        token: JWT令牌
        auth_service: 认证服务实例

    Returns:
        User: 当前用户对象

    Raises:
        HTTPException: 如果令牌无效或用户不存在
    """
    # 使用服务层验证令牌并获取用户
    user = await auth_service.get_user_by_token(token)

    if user is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="无效的身份验证凭据或用户不存在",
            headers={"WWW-Authenticate": "Bearer"},
        )

    if not user.is_active:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="用户已被禁用",
            headers={"WWW-Authenticate": "Bearer"},
        )

    return user


# 检查管理员权限的依赖项
async def is_admin(
    current_user: User = Depends(get_current_user),
    auth_service: AuthService = Depends(get_auth_service)
) -> User:
    """
    验证用户是否为管理员的依赖函数

    Args:
        current_user: 当前用户对象
        auth_service: 认证服务实例

    Returns:
        User: 当前用户对象（如果是管理员）

    Raises:
        HTTPException: 如果用户不是管理员
    """
    # 使用服务层验证管理员权限
    is_admin_user = await auth_service.validate_admin(current_user)

    if not is_admin_user:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="权限不足，需要管理员权限",
        )

    return current_user


rag\src\rag\llm_clients.py
"""
LLM客户端集合

此模块集中管理所有大语言模型客户端实例，为不同任务提供专用的LLM客户端。
这样可以为不同任务配置不同的模型和API端点，而不需要在每个地方重复配置。
"""

from langchain_openai import ChatOpenAI

# 使用统一的日志配置
from .logging_config import get_logger
from . import config # 新增配置导入
logger = get_logger("llm_clients")

# 创建主要RAG系统使用的LLM客户端
def create_rag_llm():
    """创建RAG系统使用的LLM客户端实例"""
    return ChatOpenAI(
        model=config.RAG_LLM_MODEL,
        base_url=config.RAG_BASE_URL,
        api_key=config.RAG_API_KEY,
        temperature=config.RAG_TEMPERATURE
    )

# 创建对话标题生成使用的LLM客户端
def create_title_generation_llm():
    """创建标题生成使用的LLM客户端实例"""
    return ChatOpenAI(
        model=config.TITLE_LLM_MODEL,
        base_url=config.TITLE_BASE_URL,
        api_key=config.TITLE_API_KEY,
        temperature=config.TITLE_TEMPERATURE
    )

# 创建元数据匹配使用的LLM客户端
def create_metadata_matching_llm():
    """创建元数据匹配使用的LLM客户端实例"""
    return ChatOpenAI(
        model=config.METADATA_LLM_MODEL,
        base_url=config.METADATA_BASE_URL,
        api_key=config.METADATA_API_KEY,
        temperature=config.METADATA_TEMPERATURE
    )

# 创建意图分类使用的LLM客户端
def create_intent_classification_llm():
    """创建意图分类使用的LLM客户端实例"""
    return ChatOpenAI(
        model=config.INTENT_LLM_MODEL,
        base_url=config.INTENT_BASE_URL,
        api_key=config.INTENT_API_KEY,
        temperature=config.INTENT_TEMPERATURE
    )

# 创建查询扩展使用的LLM客户端
def create_query_expansion_llm():
    """创建查询扩展使用的LLM客户端实例"""
    return ChatOpenAI(
        model=config.QUERY_EXPANSION_LLM_MODEL,
        base_url=config.QUERY_EXPANSION_BASE_URL,
        api_key=config.QUERY_EXPANSION_API_KEY,
        temperature=config.QUERY_EXPANSION_TEMPERATURE
    )

# 添加一个私有字典来缓存LLM实例
_cached_llm_instances = {}

# 获取当前活跃的LLM实例
def get_active_llm(task_type="rag", llm_dict=None):
    """
    根据任务类型获取相应的LLM客户端实例

    Args:
        task_type: 任务类型，可选值包括 "rag"(默认), "title", "metadata", "intent"
        llm_dict: 可选的LLM字典，如果提供则从中获取LLM实例

    Returns:
        对应任务类型的LLM客户端实例
    """
    global _cached_llm_instances

    # 如果提供了llm_dict，从中获取LLM实例
    if llm_dict is not None:
        if task_type in llm_dict:
            return llm_dict[task_type]

    # 如果没有提供llm_dict，尝试从缓存中获取
    if task_type in _cached_llm_instances:
        return _cached_llm_instances[task_type]

    # 如果缓存中也没有，创建新的实例并缓存
    if task_type == "title":
        _cached_llm_instances[task_type] = create_title_generation_llm()
    elif task_type == "metadata":
        _cached_llm_instances[task_type] = create_metadata_matching_llm()
    elif task_type == "intent":
        _cached_llm_instances[task_type] = create_intent_classification_llm()
    elif task_type == "query_expansion":
        _cached_llm_instances[task_type] = create_query_expansion_llm()
    else:  # 默认为"rag"
        _cached_llm_instances[task_type] = create_rag_llm()

    return _cached_llm_instances[task_type]


rag\src\rag\logging_config.py
"""
日志配置模块

此模块提供统一的日志配置，确保整个应用中的日志格式和级别一致。
"""

import logging
import sys
from . import config

# 全局日志格式
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'

# 配置根日志器
logging.basicConfig(
    level=config.LOG_LEVEL,
    format=LOG_FORMAT,
    stream=sys.stdout
)

def get_logger(name):
    """
    获取指定名称的logger实例
    
    Args:
        name: logger名称，通常使用模块名称
        
    Returns:
        logging.Logger: 配置好的logger实例
    """
    logger = logging.getLogger(name)
    logger.setLevel(config.LOG_LEVEL)
    
    # 确保不会重复添加处理器
    if not logger.handlers:
        # 如果需要特殊处理，可以在这里添加
        pass
        
    return logger


rag\src\rag\main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from contextlib import asynccontextmanager
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_transformers import EmbeddingsRedundantFilter
from langchain_core.prompts import ChatPromptTemplate
import os
import sys
from pathlib import Path
from langchain_core.documents import Document
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware
from .routes import router as api_router
from .database import init_db
from . import config
# V3 阶段三：移除了 RAG_PROMPT_TEMPLATE 的导入，因为它不再用于创建传递给 RAGPipeline 的主 prompt
from .prompts import TITLE_GENERATION_PROMPT_TEMPLATE, INTENT_CLASSIFICATION_PROMPT_TEMPLATE
from .rag_pipeline.pipeline import RAGPipeline
from .rag_pipeline.retrievers.factory import RetrieverFactory
from .rag_pipeline.processors.filters import DocumentFilterManager
from .rag_pipeline.intent_processing import IntentClassifier
from .rag_pipeline.reranker import Reranker  # V3.1: 导入重排序器
from .rag_pipeline.query_enhancer import QueryEnhancer  # V3.1: 导入查询增强器
from .prompts import QUERY_EXPANSION_PROMPT_TEMPLATE  # V3.1: 导入查询扩展提示模板
from . import llm_clients  # 导入LLM客户端模块

# 初始加载环境变量
load_dotenv()
baai_path = config.BAAI_PATH
chroma_path = config.CHROMA_PATH

if not os.path.exists(baai_path):
    print(f"Warning: BAAI_PATH {baai_path} not found, checking alternative locations...")
    local_baai_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "BAAI", "bge-large-zh-v1.5")
    if os.path.exists(local_baai_path):
        print(f"Found model at {local_baai_path}")
        baai_path = local_baai_path
    else:
        print("Using model name directly from HuggingFace")
        baai_path = "BAAI/bge-large-zh-v1.5"

@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI 应用的生命周期管理器，用于在应用启动时初始化资源。"""
    # 初始化数据库
    init_db()
    print("数据库初始化完成")

    # 初始化应用状态
    app.state.embedding = None
    app.state.vector_db = None
    app.state.llm = None

    # 初始化嵌入模型和向量数据库
    def init_embedding_and_db():
        """初始化 HuggingFace 嵌入模型和 Chroma 向量数据库。"""
        try:
            current_baai_path = config.BAAI_PATH # 使用新的配置模块
            app.state.embedding = HuggingFaceEmbeddings(
                model_name=current_baai_path,
                model_kwargs={'device': config.DEVICE}, # 使用新的配置模块
                encode_kwargs={'normalize_embeddings': True}
            )
            print(f"嵌入模型已加载: {current_baai_path}")

            current_chroma_path = config.CHROMA_PATH # 使用新的配置模块
            if not Path(current_chroma_path).exists():
                print(f"Vector database not found at {current_chroma_path}")
                raise HTTPException(status_code=500, detail=f"Vector database not found at {current_chroma_path}")

            app.state.vector_db = Chroma(
                persist_directory=current_chroma_path,
                embedding_function=app.state.embedding
            )
            print(f"向量数据库已加载: {current_chroma_path}")

            return True
        except Exception as e:
            print(f"Error initializing embedding and vector DB: {e}")
            return False

    # 初始化LLM
    def init_llm():
        """初始化所有任务所需的 LLM 客户端实例。"""
        try:
            # 导入LLM客户端创建函数
            from .llm_clients import create_rag_llm, create_title_generation_llm, create_metadata_matching_llm, create_intent_classification_llm

            # 创建新的LLM客户端实例
            rag_llm = create_rag_llm()
            title_llm = create_title_generation_llm()
            metadata_llm = create_metadata_matching_llm()
            intent_llm = create_intent_classification_llm()

            # 将app.state.llm初始化为一个字典，包含所有新创建的LLM客户端
            app.state.llm = {
                "rag": rag_llm,
                "title": title_llm,
                "metadata": metadata_llm,
                "intent": intent_llm
            }

            # 获取主RAG模型名称用于日志
            model_name = getattr(rag_llm, "model_name", None)
            if model_name is None:
                # 尝试获取其他可能的属性名
                model_name = getattr(rag_llm, "_model", getattr(rag_llm, "model_name_or_path", "未知模型"))

            print(f"LLM已加载: {model_name}")
            return True
        except Exception as e:
            print(f"Error initializing LLM: {e}")
            return False

    # 配置热重载逻辑已移除

    # 初始化组件
    if not init_embedding_and_db():
        sys.exit(1)

    if not init_llm():
        sys.exit(1)

    # 从配置中读取一次 k 值
    retriever_k_value = config.RETRIEVER_INITIAL_K # 使用新的配置模块
    print(f"Retriever K value set to: {retriever_k_value}")

    # 准备文档
    metadatas = app.state.vector_db.get()["metadatas"]
    documents_content = app.state.vector_db.get()["documents"]
    all_documents = [
        Document(page_content=content, metadata=metadata)
        for content, metadata in zip(documents_content, metadatas)
    ]

    # RetrieverFactory 和 ensemble_retriever 的创建已移除，
    # 因为 app.state.ensemble 不再需要，且 RAGPipeline 内部处理其检索器。
    # 创建冗余过滤器
    redundant_filter = DocumentFilterManager.create_redundant_filter(
        app.state.embedding
    )

    # 创建提示模板
    # V3 阶段三：为 RAGPipeline 中的 LLMChain 提供一个简单的模板，
    # 因为完整的 Prompt 已在 pipeline 内部由 format_unified_rag_prompt 构建。
    # LLMChain 的输入将是 {"question": final_prompt_string, "chat_history": ...}
    simple_llm_prompt = ChatPromptTemplate.from_template("{question}")
    title_prompt = ChatPromptTemplate.from_template(TITLE_GENERATION_PROMPT_TEMPLATE)
    intent_prompt = ChatPromptTemplate.from_template(INTENT_CLASSIFICATION_PROMPT_TEMPLATE)

    # 创建意图分类器
    intent_classifier = IntentClassifier(app.state.llm["intent"])

    # 创建重排序器
    reranker = Reranker(
        model_name=config.RERANK_MODEL_NAME,
        device_str=config.DEVICE
    )

    # 创建查询增强器
    # 创建专用的查询扩展LLM客户端
    query_expansion_llm = llm_clients.create_query_expansion_llm()
    app.state.llm["query_expansion"] = query_expansion_llm

    query_enhancer = QueryEnhancer(
        llm=query_expansion_llm,  # 使用专用的查询扩展LLM
        expansion_prompt_template_str=QUERY_EXPANSION_PROMPT_TEMPLATE
    )

    # 移除旧的 RetrieverFactory 实例化，RAGPipeline 将在内部创建它

    # 获取 k 值用于 RAGPipeline 初始化 - 已移到前面统一读取

    # 创建RAG Pipeline
    # RAGPipeline 的 __init__ 已修改，不再接受 retriever_factory
    # 而是接受 vector_db, documents, metadata_llm, k
    rag_pipeline = RAGPipeline(
        vector_db=app.state.vector_db,
        documents=all_documents,
        metadata_llm=app.state.llm["metadata"],
        k=retriever_k_value, # 使用统一的 k 值
        filter=redundant_filter,
        llm=app.state.llm["rag"],
        prompt=simple_llm_prompt, # 使用 V3 调整后的简单模板
        title_llm=app.state.llm["title"],
        title_prompt=title_prompt,
        intent_classifier=intent_classifier,
        reranker=reranker,  # V3.1: 添加重排序器
        query_enhancer=query_enhancer  # V3.1: 添加查询增强器
    )

    # 保存组件到应用状态
    app.state.filter = redundant_filter
    app.state.prompt = simple_llm_prompt # 确保 app.state 也使用更新后的 prompt
    app.state.intent_classifier = intent_classifier
    app.state.reranker = reranker  # V3.1: 保存重排序器
    app.state.query_enhancer = query_enhancer  # V3.1: 保存查询增强器
    app.state.rag_pipeline = rag_pipeline

    print("应用初始化完成") # 移除了热重载逻辑
    yield

app = FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=config.CORS_ALLOWED_ORIGINS, # 使用新的配置模块
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 添加API路由
app.include_router(api_router)

class QueryRequest(BaseModel):
    query: str

class AnswerResponse(BaseModel):
    answer: str


# 移除了未使用的 import_time 函数

rag\src\rag\run.py
import os

def find_py_files(directory='.'):
    """查找指定目录及其子目录中的所有.py文件"""
    py_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                py_files.append(os.path.join(root, file))
    return py_files

def get_relative_path_from_spectrum(filepath):
    """获取文件相对于spectrum根目录的路径"""
    abs_path = os.path.abspath(filepath)
    parts = abs_path.replace('/', '\\').split('\\')
    
    try:
        spectrum_index = parts.index('rag')
        relative_path = '\\'.join(parts[spectrum_index:])
        return relative_path
    except ValueError:
        # 如果路径中没有"spectrum"目录，则返回原始路径
        return filepath.replace('/', '\\')

def main():
    # 查找所有Python文件
    py_files = find_py_files()
    
    # 创建prompt.txt文件
    with open('prompt.txt', 'w', encoding='utf-8') as output_file:
        for i, py_file in enumerate(py_files):
            # 获取相对于spectrum的路径
            relative_path = get_relative_path_from_spectrum(py_file)
            
            # 读取Python文件内容
            try:
                with open(py_file, 'r', encoding='utf-8') as file:
                    content = file.read()
                
                # 写入prompt.txt
                output_file.write(f"{relative_path}\n")
                output_file.write(f"{content}\n\n")
            except Exception as e:
                output_file.write(f"{relative_path}\n")
                output_file.write(f"Error reading file: {str(e)}\n\n")
    
    print(f"已将{len(py_files)}个.py文件的内容写入prompt.txt")

if __name__ == "__main__":
    main()

rag\src\rag\__init__.py


rag\src\rag\prompts\intent_classification_prompt.py
"""
意图分类的prompt模板

此模块定义了用于意图分类的prompt模板，用于从用户查询中识别意图。
"""

# 意图分类的prompt模板
INTENT_CLASSIFICATION_PROMPT_TEMPLATE = """
请分析以下用户提出的Minecraft相关问题，并判断用户的意图。

首先，你需要判断问题是关于原版Minecraft还是模组：
- 如果问题涉及原版Minecraft内容，必须包含"find_vanilla_wiki"意图
- 如果问题涉及任何模组内容，必须包含"find_mod_info"意图

可用意图列表：
1. query_item: 用户想查询某个具体物品、生物、方块、群系、设定、附魔、维度、BUFF等的信息。
2. find_tutorial: 用户想查找某个操作、事件或模组内容的教程。
3. find_mod_info: 用户想了解某个模组的整体信息或推荐。此意图必须包含在所有与模组相关的问题中。
4. find_crafting_recipe: 用户想知道如何合成某个物品。
5. find_vanilla_wiki: 用户的问题与原版Minecraft内容相关。此意图必须包含在所有与原版Minecraft相关的问题中。
6. comprehensive_answer: 用户的问题比较抽象、开放，或需要结合多方面知识进行推理和回答。
7. chit_chat: 用户只是在打招呼或进行无具体Minecraft内容的闲聊。

以下是一些用户查询及其对应意图的示例：

用户查询: "你好。"
意图: ["chit_chat"]

用户查询: "怎么打败虚空守望者。"
意图: ["query_item", "find_tutorial", "find_mod_info"]

用户查询: "有没有种菜模组。"
意图: ["find_mod_info"]

用户查询: "如果我想在1.21建造一个袭击塔要如何做，利用哪些机制。"
意图: ["find_tutorial", "comprehensive_answer", "find_vanilla_wiki"]

用户查询: "在Minecraft 1.9中如何合成一个盾牌？"
意图: ["find_crafting_recipe", "query_item", "find_vanilla_wiki"]

用户查询: "tnt复制是不是在最近的一个快照版被修复了？"
意图: ["comprehensive_answer", "find_vanilla_wiki"]

用户查询: "虚无世界3最好的武器是什么"
意图: ["comprehensive_answer", "query_item", "find_mod_info"]

用户查询: "潜影贝的瞬移要满足哪些条件？"
意图: ["query_item", "find_vanilla_wiki"]

用户查询: "冰火传说的龙一般情况龙食吃了是不是直接加一天成长天数？"
意图: ["query_item", "find_mod_info"]

用户查询: "有神奇宝贝为主题的模组推荐吗？"
意图: ["find_mod_info"]

请分析以下用户最新提出的问题，并根据上述意图列表和示例，判断用户的意图。
请记住以下重要规则：
1. 如果问题涉及原版Minecraft内容，必须包含"find_vanilla_wiki"意图
2. 如果问题涉及任何模组内容，必须包含"find_mod_info"意图
3. 如果不确定是原版还是模组，请根据问题中的关键词和上下文判断
4. 一个问题可以同时包含多个意图

请使用以下格式返回结果，确保返回的是有效的JSON格式：

{{"intents": ["意图1", "意图2", ...]}}

例如：{{"intents": ["query_item", "find_tutorial", "find_mod_info"]}}

如果用户只是闲聊或意图不明，则返回 {{"intents": ["chit_chat"]}} 或 {{"intents": []}}

用户最新问题: {query}
分析结果 (JSON格式):
"""


rag\src\rag\prompts\metadata_matching_prompt.py
"""
元数据匹配的prompt模板

此模块定义了用于元数据匹配检索器的prompt模板，用于从查询中提取实体。
"""

# 元数据匹配的prompt模板
METADATA_MATCHING_PROMPT_TEMPLATE = """
请从以下Minecraft相关的查询中提取可能的模组名称（mod_names）和物品名称（item_names）。
**重要定义：**
*   **物品名称 (item_names):** 指的是 Minecraft 游戏内具体的、可交互的实体，例如方块、物品、生物、效果等。它们不仅仅是普通名词，而是代表游戏中的特定概念。
*   **模组名称 (mod_names):** 指的是添加新内容到 Minecraft 的模组的名称。

请仔细分析查询上下文，判断词语是否代表游戏内的具体实体或模组。
如果无法确定，请返回空列表。请严格以JSON格式返回，包含两个字段：mod_names和item_names。

**查询:** {query}

**JSON格式和示例:**

```json
// 查询： "我的世界怎么获得潮涌核心"
// JSON 输出：
{{
    "mod_names": [],
    "item_names": ["潮涌核心"]
}}

// 查询： "工业2的采矿机怎么用？"
// JSON 输出：
{{
    "mod_names": ["工业2"],
    "item_names": ["采矿机"]
}}

// 查询： "给我看看钻石剑"
// JSON 输出：
{{
    "mod_names": [],
    "item_names": ["钻石剑"]
}}

// 查询： "暮色森林有什么好玩的？"
// JSON 输出：
{{
    "mod_names": ["暮色森林"],
    "item_names": []
}}

// 查询： "我想了解一下村民交易"
// JSON 输出：
{{
    "mod_names": [],
    "item_names": ["村民"] // "村民" 是游戏内的具体实体
}}
```
"""


rag\src\rag\prompts\query_expansion_prompt.py
# src/rag/prompts/query_expansion_prompt.py
"""
该模块定义了用于查询扩展的提示模板。
查询扩展旨在通过LLM生成更精确的搜索表达，提高检索相关文档的能力。
"""

QUERY_EXPANSION_PROMPT_TEMPLATE = """\
你是一个专门为《我的世界》(Minecraft)领域设计的查询扩展助手。你的任务是分析用户的原始查询，理解其核心意图，然后生成一个经过优化的搜索查询，以便更好地从知识库中检索相关信息。

请按照以下步骤进行：
1. 分析用户的原始查询，识别核心主题和意图
2. 创建一个扩展的核心查询，它应该是一个完整、自然的问题，保持原始意图但更清晰、更具体
3. 识别3-5个与查询相关的Minecraft术语、概念或同义词，包括可能的变体和相关概念
4. 将扩展的核心查询和关键词合并成一个单一的搜索字符串

重要规则：
- 保持原始查询的核心意图，但可以适当扩展相关概念以提高检索效果
- 关键词应该包括直接相关的术语，以及可能的相关概念和变体，但不要过多
- 最终扩展查询的长度应控制在原始查询长度的2倍之内
- 如果查询涉及原版Minecraft，添加"原版"、"vanilla"等关键词
- 如果查询涉及模组，确保包含模组名称及其常见缩写或别名作为关键词
- 考虑添加与查询相关的游戏版本号、更新名称或相关机制

你的最终输出应该是一个单一的字符串，包含扩展的核心查询，后跟重要的关键词。不要使用任何分隔符或标签，只需输出最终的扩展查询字符串。

以下是一些示例：

原始查询: "mek通用机械怎么发电快？"
思考过程: 用户想了解Mekanism(通用机械)模组中高效发电的方法。我应该扩展为一个完整的问题，并添加相关关键词，包括模组名称的变体和主要发电机制。
扩展查询: 通用机械mod中最高效的发电方法是什么 mekanism mek 聚变反应堆 太阳能发电 风力发电机 热力发电机 能量网络 RF能量

原始查询: "找个类似匠魂的模组"
思考过程: 用户想寻找与Tinkers' Construct(匠魂)类似的模组。我需要创建一个明确的问题，并添加相关术语，包括匠魂的主要特性和可能的替代模组。
扩展查询: 有哪些功能类似匠魂的模组推荐 Tinkers Construct 匠魂 工具自定义 模块化武器 装备合成 材料融合 工具升级 Tetra Silent Gear

原始查询: "末影龙打法"
思考过程: 用户想了解如何击败Minecraft中的末影龙boss。这是原版内容，我需要创建一个关于战斗策略的问题，并添加相关术语，包括战斗机制和装备。
扩展查询: 如何有效击败Minecraft中的末影龙 原版 vanilla boss战 末地 末影水晶 水晶塔 龙息 末影珍珠 弓箭 钻石剑 盾牌 战斗技巧

原始查询: "红石电路怎么做自动门"
思考过程: 用户想学习如何使用红石电路制作自动门。这是原版内容，我需要创建一个关于红石机制的问题，并添加相关组件和设计类型。
扩展查询: 如何使用红石电路制作高效的自动门 原版 vanilla 活塞门 感应门 红石中继器 红石比较器 触发机制 压力板 绊线钩 观察者方块 门类型

原始查询: "{original_query}"
扩展查询: \
"""


rag\src\rag\prompts\rag_prompt.py
"""
RAG系统的主要prompt模板

此模块定义了用于RAG系统的主要prompt模板，用于生成对用户查询的回答。
"""

# RAG系统的主要prompt模板
RAG_PROMPT_TEMPLATE = """
你是一个专业的Minecraft模组专家，请根据以下提供的上下文信息回答用户问题。

以下是之前的对话历史：
{chat_history}

上下文信息:
{context}

用户问题: {question}

回答要求:
1. 如果找不到足够信息回答问题，直接说明"我没有足够信息回答这个问题"，不要编造
2. 仅使用上下文中的事实信息，不要添加不在上下文中的细节
3. 专注于用户问题的核心，提供简明扼要的答案
4. 使用中文Markdown格式，保持回答结构清晰
5. 引用源数据中的精确数值
6. 对于参考的文档，请在回答最后附上它的源网址
"""


rag\src\rag\prompts\title_generation_prompt.py
"""
对话标题生成的prompt模板

此模块定义了用于生成对话标题的prompt模板。
"""

# 对话标题生成的prompt模板
TITLE_GENERATION_PROMPT_TEMPLATE = """
请根据用户的下面这条消息，生成一个简短的对话标题（不超过10个字）：

{query}
"""


rag\src\rag\prompts\unified_rag_prompt.py
# src/rag/prompts/unified_rag_prompt.py
"""
该模块定义了统一的 RAG 提示模板以及一个用于格式化该模板的辅助函数。
此提示旨在处理来自用户的多个意图以及从不同检索器聚合的上下文信息。
"""

from typing import List

UNIFIED_RAG_PROMPT_TEMPLATE = """你是一个专业的Minecraft模组专家，请根据以下提供的用户问题、已识别的用户意图以及相关的上下文信息，生成一个全面且有条理的回答。

用户问题: "{original_query}"

根据分析，用户的意图可能包括: {list_of_intents_as_string}

相关上下文信息 (已根据意图检索并整合):
{aggregated_context_string}

请综合以上所有信息，提供一个清晰、准确且全面的回答。确保你的回答能够覆盖用户问题中体现出的所有主要意图。
如果某些方面的信息在上下文中找不到，请直接说明你没有足够的信息来回答那部分问题。
请使用中文 Markdown 格式进行回答。对于引用的信息，请在回答的末尾（只选取一点引用的信息）或相关内容旁（引用了很多处信息）恰当注明来源链接，可以给出多个相关来源。

{intent_specific_instructions}
"""

def format_unified_rag_prompt(
    original_query: str,
    intents: List[str],
    aggregated_context: str
) -> str:
    """
    使用给定的原始查询、识别出的意图列表和聚合的上下文字符串来格式化统一 RAG 提示模板。

    参数:
        original_query: 用户的原始查询字符串。
        intents: 由意图分类器识别出的意图字符串（标识符）列表。
                 例如: ["query_item", "find_tutorial"]
        aggregated_context: 一个包含所有从特化检索器聚合而来的相关上下文信息的字符串，
                            可能带有来源标记。

    返回:
        一个格式化后的字符串，可以直接发送给大语言模型 (LLM)。
    """
    list_of_intents_as_string: str

    if not intents or ("chit_chat" in intents and len(intents) == 1): # 处理闲聊或意图列表为空的情况
        # 对于闲聊意图，可能根本不会使用此完整提示，或者会使用一个更简单的提示。
        # 但如果确实使用此提示，意图描述应保持简洁。
        if "chit_chat" in intents:
            list_of_intents_as_string = "进行一般性的闲聊。"
        else: # 空的意图列表
            list_of_intents_as_string = "用户意图不明确或需要综合理解。"
    else:
        # 如果存在其他意图，则过滤掉闲聊意图
        active_intents = [intent for intent in intents if intent != "chit_chat"]
        # 此处不再需要 if not active_intents 检查，因为如果 active_intents 为空，
        # 意味着原始 intents 为空或仅包含 chit_chat，这些情况已在上面的 if 块中处理。

        # 尝试为意图创建一个更自然的语言描述字符串。
        # 这是一个简化的启发式方法，有很大的改进空间。
        # 它假设 `original_query` 可以作为意图的通用主题。
        # 一个更健壮的解决方案会涉及将提取的实体与特定意图相关联。

        intent_phrases = []
        # 为演示目的，使用基于查询的简化主题。
        # 在实际场景中，与每个意图相关的特定实体会更好。
        subject_placeholder = f"'{original_query[:30]}{'...' if len(original_query) > 30 else ''}'" # 截断以保持简洁
        for intent in active_intents:
            if intent == "query_item":
                intent_phrases.append(f"查询关于 {subject_placeholder} 的物品信息")
            elif intent == "find_tutorial":
                intent_phrases.append(f"查找关于 {subject_placeholder} 的教程")
            elif intent == "find_mod_info":
                intent_phrases.append(f"查找关于 {subject_placeholder} 的模组信息")
            elif intent == "find_crafting_recipe":
                intent_phrases.append(f"查找 {subject_placeholder} 的合成配方")
            elif intent == "find_vanilla_wiki":
                intent_phrases.append(f"从Minecraft Wiki获取关于 {subject_placeholder} 的信息")
            elif intent == "comprehensive_answer":
                intent_phrases.append(f"对 {subject_placeholder} 提供一个综合性的解答")
            else:
                # 未知或新意图的备用处理方式
                intent_phrases.append(f"处理与 {intent} 相关的请求，特别是关于 {subject_placeholder}")

        # 此处不再需要 if not intent_phrases 检查，
        # 因为如果 active_intents 非空，intent_phrases 也必然非空（至少会进入 fallback）。
            # 根据 intent_phrases 的数量格式化字符串
            if len(intent_phrases) == 1:
                list_of_intents_as_string = intent_phrases[0] + "。"
            elif len(intent_phrases) == 2:
                # 格式: "意图A，并且意图B。" (保持 .lower() 行为)
                list_of_intents_as_string = f"{intent_phrases[0]}，并且{intent_phrases[1].lower()}。"
            else: # len(intent_phrases) > 2 (因为 intent_phrases 不会为空，且已处理 len=1 和 len=2)
                # 格式: "意图A、意图B，并且意图C。" (保持 .lower() 行为)
                list_of_intents_as_string = f"{'、'.join(intent_phrases[:-1])}，并且{intent_phrases[-1].lower()}。"

    # 添加意图特定的指令
    intent_specific_instructions = generate_intent_specific_instructions(intents, original_query)

    return UNIFIED_RAG_PROMPT_TEMPLATE.format(
        original_query=original_query,
        list_of_intents_as_string=list_of_intents_as_string,
        aggregated_context_string=aggregated_context,
        intent_specific_instructions=intent_specific_instructions
    )

def generate_intent_specific_instructions(intents: List[str], query: str) -> str:
    """
    根据识别出的意图生成特定的指令。

    参数:
        intents: 意图列表
        query: 原始查询

    返回:
        特定意图的指令字符串
    """
    if not intents or ("chit_chat" in intents and len(intents) == 1):
        return ""  # 闲聊不需要特定指令

    # 过滤掉闲聊意图
    active_intents = [intent for intent in intents if intent != "chit_chat"]
    if not active_intents:
        return ""

    instructions = []

    # 检查是否只有原版内容
    only_vanilla = "find_vanilla_wiki" in active_intents and "find_mod_info" not in active_intents

    # 1. 只对原版提问的内容不能包括模组的内容
    if only_vanilla:
        instructions.append("请只提供原版Minecraft的信息，不要包含任何模组内容。如果上下文中包含模组信息，请忽略这些信息。")

    # 2. 教程类提问需要给出清晰的流程
    if "find_tutorial" in active_intents:
        instructions.append("请提供清晰的步骤说明，使用有序列表格式（1. 2. 3.），确保步骤易于理解和执行。如果有多种方法，请分别列出。")

    # 3. 物品类需要给出物品信息
    if "query_item" in active_intents:
        instructions.append("对于物品信息，请包括其基本属性、用途和获取方式。如果是工具或武器，请说明其耐久、伤害或特殊效果。")

    # 4. 合成配方需要明确列出材料
    if "find_crafting_recipe" in active_intents:
        instructions.append("对于合成配方，请明确列出所需材料及其数量，并简要描述合成方法（工作台、熔炉等）。如果可能，用文字描述合成表格布局。")

    # 5. 模组信息需要明确指出
    if "find_mod_info" in active_intents:
        instructions.append("请明确指出哪些内容来自模组，并注明模组名称。如果涉及多个模组，请分别说明各个模组的相关内容。")

    # 6. 综合性回答需要全面且有条理
    if "comprehensive_answer" in active_intents:
        instructions.append("请提供一个全面且有条理的回答，涵盖问题的各个方面。使用小标题组织不同部分，确保逻辑清晰，并在适当的地方提供示例。")

    # 组合多个意图的特殊指令
    if len(active_intents) > 1:
        instructions.append("由于问题涉及多个方面，请确保回答涵盖所有相关意图，并使用适当的结构组织不同部分的内容。")

    # 格式化最终指令
    if instructions:
        return "特别说明：\n" + "\n".join(f"- {instr}" for instr in instructions)
    else:
        return ""


rag\src\rag\prompts\__init__.py
"""
Prompt模板集合

此模块包含应用程序中使用的所有prompt模板。
将prompt集中管理可以更容易地维护和更新它们。
"""

from .rag_prompt import RAG_PROMPT_TEMPLATE
from .title_generation_prompt import TITLE_GENERATION_PROMPT_TEMPLATE
from .metadata_matching_prompt import METADATA_MATCHING_PROMPT_TEMPLATE
from .intent_classification_prompt import INTENT_CLASSIFICATION_PROMPT_TEMPLATE
from .query_expansion_prompt import QUERY_EXPANSION_PROMPT_TEMPLATE

__all__ = [
    "RAG_PROMPT_TEMPLATE",
    "TITLE_GENERATION_PROMPT_TEMPLATE",
    "METADATA_MATCHING_PROMPT_TEMPLATE",
    "INTENT_CLASSIFICATION_PROMPT_TEMPLATE",
    "QUERY_EXPANSION_PROMPT_TEMPLATE",
]


rag\src\rag\rag_pipeline\llm_chain.py
"""
LLM链管理器模块

此模块提供了用于构建和调用LLM链的工具。
"""

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from typing import Dict, Any, AsyncIterable

class LLMChainManager:
    """
    LLM链管理器，用于构建和调用LLM链
    """
    
    @staticmethod
    def create_rag_chain(llm: ChatOpenAI, prompt: ChatPromptTemplate):
        """
        创建RAG链
        
        Args:
            llm: LLM实例
            prompt: 提示模板
            
        Returns:
            链对象
        """
        return prompt | llm
    
    # 移除了 stream_response 方法，因为 RAGPipeline.stream_llm_response 内部已实现流式调用
    # 移除了 format_sources 方法，因为 RAGPipeline.retrieve_and_format_context 内部已实现上下文格式化


rag\src\rag\rag_pipeline\pipeline.py
"""
RAG Pipeline模块

此模块提供了RAG Pipeline的核心实现，封装了检索、过滤、上下文整合、Prompt组装、LLM调用等步骤。
"""

from typing import List, Tuple, Dict, Any, AsyncIterable, Optional, Union
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI # For type hint of llm, title_llm
from langchain_core.language_models.chat_models import BaseChatModel # For metadata_llm type hint
from langchain_chroma import Chroma # For vector_db type hint
from langchain_core.retrievers import BaseRetriever
from langchain_community.document_transformers import EmbeddingsRedundantFilter
from langchain_core.prompts import ChatPromptTemplate
import json
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor
import os

from .llm_chain import LLMChainManager
from .intent_processing import IntentClassifier
from .retrievers.factory import RetrieverFactory # 导入 RetrieverFactory
from src.rag.prompts.unified_rag_prompt import format_unified_rag_prompt # V3 阶段三：导入统一 Prompt 格式化函数
from .. import config
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .reranker import Reranker
    from .query_enhancer import QueryEnhancer
# 使用统一的日志配置
from ..logging_config import get_logger
logger = get_logger("rag_pipeline")

class RAGPipeline:
    """
    RAG Pipeline类，封装检索、过滤、上下文整合、Prompt组装、LLM调用等核心步骤
    """

    def __init__(
        self,
        vector_db: Chroma,
        documents: List[Document],
        metadata_llm: BaseChatModel,
        k: int,
        filter: EmbeddingsRedundantFilter,
        llm: ChatOpenAI, # 主 LLM
        prompt: ChatPromptTemplate,
        title_llm: Optional[ChatOpenAI] = None,
        title_prompt: Optional[ChatPromptTemplate] = None,
        intent_classifier: Optional[IntentClassifier] = None,
        reranker: Optional["Reranker"] = None,  # 新增: 重排序器
        query_enhancer: Optional["QueryEnhancer"] = None  # 新增: 查询增强器
    ):
        """
        初始化 RAG Pipeline。

        参数:
            vector_db: Chroma 向量数据库实例。
            documents: 用于元数据匹配的文档列表。
            metadata_llm: 用于元数据匹配的语言模型。
            k: 检索器返回的最大文档数量。
            filter: EmbeddingsRedundantFilter 实例 (当前主要通过URL去重，此过滤器可选)。
            llm: 用于生成答案的主要 ChatOpenAI 实例。
            prompt: 用于主 RAG 链的 ChatPromptTemplate。
            title_llm: (可选) 用于生成对话标题的 ChatOpenAI 实例。
            title_prompt: (可选) 用于生成对话标题的 ChatPromptTemplate。
            intent_classifier: (可选) IntentClassifier 实例。
            reranker: (可选) 用于对检索结果进行重排序的 Reranker 实例。
            query_enhancer: (可选) 用于扩展用户查询的 QueryEnhancer 实例。
        """
        # 存储 RetrieverFactory 及其他组件可能需要的依赖项
        self.vector_db = vector_db
        self.documents = documents
        self.metadata_llm = metadata_llm
        self.k = k

        # 在 Pipeline 内部实例化 RetrieverFactory
        self.retriever_factory = RetrieverFactory(
            vector_db=self.vector_db,
            documents=self.documents,
            metadata_llm=self.metadata_llm,
            k=self.k
        )
        self.filter = filter
        self.llm = llm
        self.prompt = prompt
        self.title_llm = title_llm
        self.title_prompt = title_prompt
        self.intent_classifier = intent_classifier
        self.reranker = reranker  # 新增: 存储重排序器
        self.query_enhancer = query_enhancer  # 新增: 存储查询增强器

        # 创建LLM链
        self.chain = LLMChainManager.create_rag_chain(llm, prompt)

        # 创建线程池用于CPU密集型操作
        # 根据CPU核心数确定线程池大小，但最少2个线程，最多8个线程
        max_workers = min(max(os.cpu_count() or 2, 2), 8)
        logger.info(f"初始化 RAG Pipeline 线程池，线程数: {max_workers}")
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

    async def retrieve_and_format_context(self, query: str, original_query: str = None, intents: List[str] = None) -> Tuple[str, List[Document], List[str]]:
        """
        执行并行检索、过滤并格式化上下文

        Args:
            query: 用于检索的查询（可能是扩展后的查询）
            original_query: 用户原始查询，用于重排序（如果为None，则使用query）
            intents: 预先识别的意图列表（如果为None，则使用空列表）

        Returns:
            Tuple[str, List[Document], List[str]]: 上下文字符串、过滤后的文档列表和意图列表
        """
        # 如果未提供原始查询，则使用当前查询
        if original_query is None:
            original_query = query

        # 如果未提供意图，则使用空列表
        if intents is None:
            intents = []

        try:
            total_start_time = time.time()
            loop = asyncio.get_event_loop()

            logger.info(f"开始检索和格式化上下文 | 查询: '{query}' | 意图: {intents}")

            # 2. 获取检索器
            retrieval_start_time = time.time()
            # 根据意图获取检索器
            retrievers_to_run: List[BaseRetriever] = self.retriever_factory.get_retrievers_by_intent(intents)

            if not retrievers_to_run:
                logger.warning(f"未找到针对意图 {intents} 的特定检索器，将使用回退检索器。")
                # 使用空列表或特定回退逻辑获取回退检索器
                retrievers_to_run = self.retriever_factory.get_retrievers_by_intent([]) # 假设空列表触发回退

            # 获取要运行的检索器名称列表
            retriever_names_to_run = [getattr(r, 'source_name', r.__class__.__name__) for r in retrievers_to_run]
            logger.info("准备为查询 '%s' 并行运行 %d 个检索器: %s", query, len(retrievers_to_run), retriever_names_to_run)

            # 3. 并行执行检索
            tasks = []
            task_start_times = {} # 用于记录每个任务的开始时间
            for retriever in retrievers_to_run:
                retriever_source_name = getattr(retriever, 'source_name', retriever.__class__.__name__)
                task_name = f"{retriever_source_name}_{retriever.__class__.__name__}"

                # 记录任务开始时间
                task_start_times[task_name] = time.time()

                # 检查是否有 ainvoke 方法
                if hasattr(retriever, 'ainvoke') and callable(retriever.ainvoke):
                    # logger.debug("开始异步检索: %s", retriever_source_name) # 移除启动日志
                    tasks.append(asyncio.create_task(retriever.ainvoke(query), name=f"ainvoke_{task_name}"))
                # 否则，假定有 invoke 方法，并在线程池中运行
                elif hasattr(retriever, 'invoke') and callable(retriever.invoke):
                    # logger.debug("开始同步检索(线程池): %s", retriever_source_name) # 移除启动日志
                    # 传递 retriever.invoke 而不是 retriever.invoke(query)
                    tasks.append(asyncio.create_task(loop.run_in_executor(self.executor, retriever.invoke, query), name=f"invoke_{task_name}"))
                else:
                    logger.warning(f"检索器 {retriever_source_name} ({retriever.__class__.__name__}) 没有可调用的 'ainvoke' 或 'invoke' 方法，已跳过。")

            # 使用 asyncio.gather 并行运行所有任务
            # return_exceptions=True 使得即使某个任务失败，也能获取其他任务的结果
            results: List[Union[List[Document], Exception]] = await asyncio.gather(*tasks, return_exceptions=True)
            retrieval_time = time.time() - retrieval_start_time

            # 4. 聚合结果
            combined_docs: List[Document] = []
            successful_retrievals = 0
            failed_retrievals = 0
            for i, result in enumerate(results):
                retriever = retrievers_to_run[i]
                retriever_source_name = getattr(retriever, 'source_name', retriever.__class__.__name__)
                task_name = tasks[i].get_name() if hasattr(tasks[i], 'get_name') else f"Task_{i}" # 用于匹配开始时间
                task_end_time = time.time()
                task_duration = task_end_time - task_start_times.get(task_name.split('_', 1)[-1], task_end_time) # 获取对应任务的耗时

                if isinstance(result, Exception):
                    failed_retrievals += 1
                    logger.error(f"并行检索任务 '{task_name}' 失败: {result}", exc_info=result)
                    logger.debug("检索完成: %s | 状态: 失败 | 耗时: %.2fs", retriever_source_name, task_duration)
                elif isinstance(result, list):
                    successful_retrievals += 1
                    combined_docs.extend(result)
                    logger.debug("检索完成: %s | 状态: 成功 (%d 个文档) | 耗时: %.2fs", retriever_source_name, len(result), task_duration)
                else:
                    # 对于未知类型，也计入失败，并记录警告
                    failed_retrievals += 1
                    logger.warning(f"并行检索任务 '{task_name}' 返回了意外类型: {type(result)}")
                    logger.debug("检索完成: %s | 状态: 未知结果类型 | 耗时: %.2fs", retriever_source_name, task_duration)

            logger.info("并行检索完成 | 总耗时: %.2fs | 成功: %d | 失败: %d | 合并后文档数: %d", retrieval_time, successful_retrievals, failed_retrievals, len(combined_docs))

            # 5. 基于 URL 的去重 (在可能的高成本过滤操作之前进行)
            url_dedup_start_time = time.time()
            unique_docs_by_url: List[Document] = []
            seen_urls = set()
            num_docs_without_url = 0
            if combined_docs: # 仅在有文档时执行去重
                logger.info("开始基于 URL 去重，处理 %d 个文档...", len(combined_docs))
                for doc in combined_docs:
                    # 使用 "源网站" 作为 URL 的元数据键
                    url = doc.metadata.get("源网站")
                    # 检查 URL 是否有效
                    if url and url.strip():
                        # 规范化 URL (移除末尾斜杠)
                        normalized_url = url.rstrip('/')
                        if normalized_url not in seen_urls:
                            seen_urls.add(normalized_url)
                            unique_docs_by_url.append(doc)
                        # else: # 可选：记录被去重的文档
                        #     logger.debug("重复URL，跳过文档: %s", normalized_url)
                    else:
                        # 保留没有有效 URL 的文档
                        unique_docs_by_url.append(doc)
                        num_docs_without_url += 1
                        # logger.debug("文档无有效'源网站'URL，已保留: %s...", doc.page_content[:50])

                url_dedup_time = time.time() - url_dedup_start_time
                # 记录 URL 去重结果
                logger.info("URL 去重完成 | 耗时: %.2fs | 去重前: %d -> 去重后: %d (%d 个文档无有效'源网站'URL被保留)",
                            url_dedup_time, len(combined_docs), len(unique_docs_by_url), num_docs_without_url)
            else:
                logger.info("无文档可供检索，跳过基于 URL 的去重。")
                # 确保 unique_docs_by_url 在此情况下为空列表
                unique_docs_by_url = []
            # 5. 过滤与去重 (在线程池中执行)
            filtered_docs: List[Document] = []
            # --- 嵌入冗余过滤 (可选，当前已禁用) ---
            # 当前主要依赖前置的 URL 去重逻辑。如果需要更强的语义去重能力，
            # 可以考虑取消注释下面的代码块，并重新启用 EmbeddingsRedundantFilter。
            # 注意：若启用，可能需要仔细调整 EmbeddingsRedundantFilter 的 similarity_threshold 参数。
            # logger.info("开始进行嵌入冗余过滤，处理 %d 个文档...", len(unique_docs_by_url))
            # filter_start_time = time.time()
            # try:
            #     # # 定义同步过滤函数 (以便在线程池中运行)
            #     # def perform_filtering(docs_to_filter: List[Document]) -> List[Document]:
            #     #     return self.filter.transform_documents(docs_to_filter)
            #     #
            #     # # 在线程池中异步执行过滤操作
            #     # filtered_docs = await loop.run_in_executor(
            #     #     self.executor, perform_filtering, unique_docs_by_url
            #     # )
            #     filter_time = time.time() - filter_start_time
            #     logger.info("嵌入冗余过滤完成 | 耗时: %.2fs | 过滤前文档数: %d -> 过滤后文档数: %d", filter_time, len(unique_docs_by_url), len(filtered_docs))
            # except Exception as filter_error:
            #     logger.error("嵌入冗余过滤过程中发生错误: %s", filter_error, exc_info=True)
            #     # 在过滤失败的情况下，使用仅经过 URL 去重的文档列表作为回退机制
            #     logger.warning("由于过滤时发生错误，已回退至使用仅基于 URL 去重后的文档列表。")
            #     filtered_docs = unique_docs_by_url

            # 5.5 重排序 (Rerank)
            reranked_docs: List[Document] = []
            if unique_docs_by_url and self.reranker:
                rerank_start_time = time.time()
                logger.info(f"开始对 {len(unique_docs_by_url)} 个文档进行重排序...")
                try:
                    # 使用原始查询进行重排序，而不是可能扩展后的查询
                    reranked_docs = await self.reranker.rerank_documents(original_query, unique_docs_by_url)
                    rerank_time = time.time() - rerank_start_time
                    logger.info(f"重排序完成 | 耗时: {rerank_time:.2f}秒 | 重排序前: {len(unique_docs_by_url)} -> 重排序后: {len(reranked_docs)}")
                except Exception as rerank_error:
                    logger.error(f"重排序过程中发生错误: {rerank_error}", exc_info=True)
                    # 在重排序失败的情况下，使用 URL 去重后的文档列表作为回退
                    logger.warning("由于重排序错误，回退至使用 URL 去重后的文档")
                    reranked_docs = unique_docs_by_url[:config.RERANK_TOP_K]  # 使用配置的 TOP_K 值
            elif unique_docs_by_url:
                # 如果没有配置重排序器，但有文档，则使用 URL 去重后的前 K 个文档
                logger.info(f"未配置重排序器，使用 URL 去重后的前 {config.RERANK_TOP_K} 个文档")
                reranked_docs = unique_docs_by_url[:config.RERANK_TOP_K]
            else:
                # 如果没有文档，则保持空列表
                logger.info("无文档可供重排序")

            # 使用重排序后的文档作为基础
            filtered_docs = reranked_docs

            # 5.6 意图驱动的文档评分和排序
            scored_docs = self._score_documents_by_intent(filtered_docs, intents)
            # 按评分降序排序
            scored_docs.sort(key=lambda x: x[1], reverse=True)
            # 提取排序后的文档
            filtered_docs = [doc for doc, _ in scored_docs]
            logger.info(f"意图驱动的文档评分和排序完成 | 文档数: {len(filtered_docs)}")

            # 6. 格式化上下文
            context_parts = []
            processed_sources = set() # 跟踪已添加标题的来源组合

            for doc in filtered_docs:
                source_info = ""
                # 从元数据获取意图和原始来源信息
                intent_source = doc.metadata.get("retrieved_by_intent", "未知意图")
                original_source = doc.metadata.get("source", "未知来源")
                source_key = (intent_source, original_source)

                # 为新的来源组合添加标题
                if source_key not in processed_sources:
                    source_info = f"--- 来自意图 '{intent_source}' 的信息 (来源: {original_source}) ---\n"
                    processed_sources.add(source_key)

                # 添加文档元数据和内容
                metadata_str = json.dumps(doc.metadata, ensure_ascii=False, indent=2)
                context_parts.append(f"{source_info}[文档元数据]:\n{metadata_str}\n\n[文档内容]:\n{doc.page_content}")

            context_str = "\n\n".join(context_parts)

            # 记录总体耗时
            total_time = time.time() - total_start_time
            logger.info(f"RAG 检索与格式化总耗时: {total_time:.2f}秒")

            return context_str, filtered_docs, intents

        except Exception as e:
            logger.error(f"获取 RAG 上下文时发生意外错误: {e}", exc_info=True)
            return "", [], [] # 返回空值，确保流程继续

    async def stream_llm_response(
        self,
        chat_history_str: str,
        # context_str: str, # V3 阶段三：移除 context_str，信息已在 final_prompt_string 中
        final_prompt_string: str # V3 阶段三：接收统一后的 Prompt
    ) -> AsyncIterable[str]:
        """
        流式处理LLM调用并生成响应

        Args:
            chat_history_str: 对话历史字符串
            final_prompt_string: 经过 `format_unified_rag_prompt` 处理后的最终Prompt字符串

        Yields:
            str: 响应文本块
        """
        try:
            # 获取 LLM 模型名称 (尝试多种常见属性以提高兼容性)
            model_name = getattr(self.llm, "model_name", None) or \
                         getattr(self.llm, "_model", None) or \
                         getattr(self.llm, "model_name_or_path", "未知LLM模型")

            # 准备输入
            chain_input = {
                # "context": context_str, # V3 阶段三：上下文已包含在 final_prompt_string 中，此处的 key 取决于 self.prompt 的期望
                "chat_history": chat_history_str,
                "question": final_prompt_string # V3 阶段三：使用 final_prompt_string 作为 LLM 的主要输入
                                              # 假设 self.prompt (ChatPromptTemplate) 的输入变量包含 "question"
            }

            # 记录首次响应时间
            first_token_received = False
            llm_start_time = time.time()
            token_count = 0

            # 使用astream方法获取流式响应
            async for chunk in self.chain.astream(chain_input):
                # 提取内容
                content = chunk.content if hasattr(chunk, "content") else str(chunk)

                # 记录首个 token 的时间
                if not first_token_received and content:
                    first_token_received = True
                    first_token_time = time.time() - llm_start_time
                    logger.info(f"LLM 首次响应耗时: {first_token_time:.2f}秒")

                # 估算 token 数量
                if content:
                    token_count += len(content) / 4 # 粗略估计

                yield content

            # 记录总体LLM调用时间
            llm_total_time = time.time() - llm_start_time

            # 计算并记录 LLM 性能
            if token_count > 0 and llm_total_time > 0:
                tokens_per_second = token_count / llm_total_time
                logger.info(f"LLM 性能 | 模型: {model_name} | 总耗时: {llm_total_time:.2f}秒 | 约 {token_count:.0f} tokens | 速度: {tokens_per_second:.2f} t/s")

        except Exception as e:
            logger.error(f"流式处理查询时出错: {e}", exc_info=True)
            yield f"抱歉，处理您的问题时出现错误: {str(e)}"

    async def _process_core(
        self,
        original_query: str, # V3 阶段三：参数名明确为 original_query
        chat_history_str: str = ""
    ) -> AsyncIterable[Dict[str, Any]]:
        """
        核心查询处理逻辑，被process_query和process_new_conversation共享

        Args:
            original_query: 用户原始查询
            chat_history_str: 对话历史字符串

        Yields:
            Dict[str, Any]: 事件字典，包含事件类型和数据
        """
        try:
            # 记录开始时间
            total_start_time = time.time()
            logger.info(f"RAGPipeline._process_core: 开始处理查询: '{original_query}'")

            # 0. 真正并行执行查询扩展和意图分类（使用线程池）
            query_for_retrieval = original_query
            intents = []

            # 创建包装函数，在独立线程中运行异步任务
            async def run_async_in_thread(async_func, *args):
                """在独立线程中运行异步函数"""
                # 创建一个可在线程中运行的同步函数
                def run_in_new_thread():
                    # 创建新的事件循环
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        # 在新循环中运行异步函数
                        return new_loop.run_until_complete(async_func(*args))
                    finally:
                        new_loop.close()

                # 在线程池中运行同步函数
                loop = asyncio.get_running_loop()
                return await loop.run_in_executor(self.executor, run_in_new_thread)

            # 准备并行任务
            parallel_tasks = []
            task_names = []

            # 添加查询扩展任务
            if self.query_enhancer:
                logger.info("RAGPipeline._process_core: 开始真正并行查询扩展（线程池）")
                query_expansion_task = run_async_in_thread(
                    self.query_enhancer.expand_query, original_query
                )
                parallel_tasks.append(query_expansion_task)
                task_names.append("查询扩展")
            else:
                logger.info("RAGPipeline._process_core: 未配置查询增强器，使用原始查询")
                # 添加一个返回原始查询的占位任务
                parallel_tasks.append(asyncio.sleep(0, result=original_query))
                task_names.append("查询扩展（占位）")

            # 添加意图分类任务
            if self.intent_classifier:
                logger.info("RAGPipeline._process_core: 开始真正并行意图分类（线程池）")
                intent_classification_task = run_async_in_thread(
                    self.intent_classifier.classify_intent, original_query
                )
                parallel_tasks.append(intent_classification_task)
                task_names.append("意图分类")
            else:
                logger.info("RAGPipeline._process_core: 未配置意图分类器，使用空意图列表")
                # 添加一个返回空列表的占位任务
                parallel_tasks.append(asyncio.sleep(0, result=[]))
                task_names.append("意图分类（占位）")

            # 并行执行任务
            parallel_start_time = time.time()
            results = await asyncio.gather(*parallel_tasks, return_exceptions=True)
            parallel_time = time.time() - parallel_start_time
            logger.info(f"RAGPipeline._process_core: 真正并行任务完成，耗时: {parallel_time:.2f}秒")

            # 处理任务结果
            for i, (result, task_name) in enumerate(zip(results, task_names)):
                if isinstance(result, Exception):
                    logger.error(f"{task_name}失败: {result}", exc_info=result)
                else:
                    logger.info(f"{task_name}成功完成")

            # 处理查询扩展结果
            if not isinstance(results[0], Exception):
                query_for_retrieval = results[0]
                if query_for_retrieval != original_query:
                    logger.info(f"RAGPipeline._process_core: 查询已扩展为: '{query_for_retrieval}'")
                else:
                    logger.info("RAGPipeline._process_core: 查询扩展未改变原始查询")
            else:
                logger.warning("由于查询扩展失败，使用原始查询")

            # 处理意图分类结果
            if len(parallel_tasks) > 1 and not isinstance(results[1], Exception):
                intents = results[1]
                logger.info(f"RAGPipeline._process_core: 意图分类结果: {intents}")
            else:
                logger.warning("由于意图分类失败或未配置，使用空意图列表")

            # 1. 获取上下文 (使用并行任务的结果)
            # V3.1: 使用扩展后的查询进行检索，但传递原始查询用于重排序，并传递已识别的意图
            aggregated_context_string, _, _ = await self.retrieve_and_format_context(
                query=query_for_retrieval,
                original_query=original_query,
                intents=intents
            )
            logger.info(f"RAGPipeline._process_core: 接收到的原始查询: '{original_query}', 识别出的意图: {intents}")

            # 2. Chit-chat 快速路径 (V3 阶段三，步骤 4)
            if intents == ["chit_chat"]:
                logger.info("RAGPipeline._process_core: 检测到 'chit_chat' 意图，使用快速路径。")
                chit_chat_response = "你好！有什么我可以帮助你的吗？" # 预设的友好中文闲聊回应
                yield {"event": "message", "data": chit_chat_response}
                yield {"event": "end", "data": ""}
                # 记录LLM（此处为预设）响应
                logger.info(f"RAGPipeline._process_core: Chit-chat 路径响应长度: {len(chit_chat_response)}")
                total_time = time.time() - total_start_time
                logger.info(f"RAGPipeline._process_core: Chit-chat 路径处理总耗时: {total_time:.2f}秒")
                return

            # 3. 主 RAG 路径 (V3 阶段三，步骤 2)
            logger.info(f"RAGPipeline._process_core: 进入主 RAG 路径。")
            logger.info(f"RAGPipeline._process_core: retrieve_and_format_context 返回的 aggregated_context_string 长度: {len(aggregated_context_string)}")

            # 构建统一 Prompt
            final_prompt_string = format_unified_rag_prompt(
                original_query=original_query,
                intents=intents,
                aggregated_context=aggregated_context_string
            )
            #出于安全和隐私考虑，开发阶段记录完整Prompt，生产环境可以考虑截断或哈希
            logger.info(f"RAGPipeline._process_core: 生成的 final_prompt_string (前500字符): {final_prompt_string[:500]}...")
            logger.info(f"RAGPipeline._process_core: 生成的 final_prompt_string 长度: {len(final_prompt_string)}")


            # 流式生成响应 - 将 final_prompt_string 传递给 LLM
            # stream_llm_response 的签名和内部逻辑也需要相应调整
            full_response_content = []
            async for chunk in self.stream_llm_response(chat_history_str, final_prompt_string): # 注意参数变化
                if chunk:
                    full_response_content.append(chunk)
                    # 发送消息块事件
                    yield {"event": "message", "data": chunk}

            final_answer = "".join(full_response_content)
            logger.info(f"RAGPipeline._process_core: LLM 返回的最终答案长度: {len(final_answer)}")
            if len(final_answer) > 100:
                logger.info(f"RAGPipeline._process_core: LLM 返回的最终答案摘要 (前100字符): {final_answer[:100]}...")
            else:
                logger.info(f"RAGPipeline._process_core: LLM 返回的最终答案: {final_answer}")


            # 流结束
            yield {"event": "end", "data": ""}

            # 记录总体耗时
            total_time = time.time() - total_start_time
            logger.info(f"RAGPipeline._process_core: 主 RAG 路径处理总耗时: {total_time:.2f}秒")

            # 注意: 异步生成器通过 yield 传递数据，不能使用 return 返回值

        except Exception as e:
            logger.error(f"处理查询 '_process_core' 时出错: {e}", exc_info=True)
            # 发送错误事件
            yield {"event": "error", "data": json.dumps({"message": f"处理回复时发生错误: {str(e)}"})}
            # 异步生成器不能使用return返回值

    async def process_query(
        self,
        query: str,
        chat_history_str: str = ""
    ) -> AsyncIterable[Dict[str, Any]]:
        """
        处理查询并生成事件流

        Args:
            query: 用户查询
            chat_history_str: 对话历史字符串

        Yields:
            Dict[str, Any]: 事件字典，包含事件类型和数据
        """
        # 调用核心处理逻辑
        async for event in self._process_core(original_query=query, chat_history_str=chat_history_str): # V3 阶段三：确保参数名一致
            yield event

    async def generate_title(self, query: str) -> str:
        """
        生成对话标题

        Args:
            query: 用户查询

        Returns:
            str: 生成的标题
        """
        # 记录开始时间
        start_time = time.time()

        if self.title_llm is None or self.title_prompt is None:
            # 如果没有提供标题生成组件，使用查询的前15个字符作为标题
            if len(query) > 15:
                title = query[:12] + "..."
            else:
                title = query
            return title

        try:
            # 获取标题生成 LLM 模型名称 (尝试多种常见属性以提高兼容性)
            model_name = getattr(self.title_llm, "model_name", None) or \
                         getattr(self.title_llm, "_model", None) or \
                         getattr(self.title_llm, "model_name_or_path", "未知标题LLM模型")

            # 创建处理链
            from langchain_core.output_parsers import StrOutputParser
            title_chain = (
                self.title_prompt
                | self.title_llm
                | StrOutputParser()
            )

            # 定义同步函数以便在线程池中执行
            def generate_title_sync():
                raw_title = title_chain.invoke({"query": query})
                # 清理标题中的引号
                return raw_title.strip().replace("\"", "").replace("'", "")

            # 在线程池中异步执行标题生成
            loop = asyncio.get_event_loop()
            title = await loop.run_in_executor(self.executor, generate_title_sync)
            # 限制标题长度
            if len(title) > 30:
                title = title[:27] + "..."

            # 记录总体耗时
            title_time = time.time() - start_time
            logger.info(f"标题生成 | 模型: {model_name} | 耗时: {title_time:.2f}秒 | 标题: '{title}'")

            return title
        except Exception as e:
            logger.error(f"生成标题时出错: {e}", exc_info=True) # 添加 exc_info
            # 出错时使用截断的查询作为回退标题
            title = query[:12] + "..." if len(query) > 15 else query
            return title

    async def process_new_conversation(
        self,
        query: str
    ) -> Tuple[str, AsyncIterable[Dict[str, Any]]]:
        """
        处理新对话

        Args:
            query: 用户查询

        Returns:
            Tuple[str, AsyncIterable[Dict[str, Any]]]: 初始标题和事件生成器
        """
        # 记录开始时间
        start_time = time.time()

        # 使用查询前缀作为初始标题
        initial_title = query[:15] + "..." if len(query) > 15 else query

        # 定义事件生成器
        async def event_generator() -> AsyncIterable[Dict[str, Any]]:
            # 调用核心处理逻辑
            async for event in self._process_core(original_query=query, chat_history_str=""):  # V3 阶段三：确保参数名一致，新对话历史为空
                yield event

                # 在流结束后生成并发送最终标题
                if event["event"] == "end":
                    generated_title = await self.generate_title(query) # 此处会记录标题生成日志
                    yield {"event": "title_update", "data": json.dumps({"title": generated_title})}

                    # 记录总体耗时
                    total_time = time.time() - start_time
                    logger.info(f"新对话处理总耗时: {total_time:.2f}秒")

        return initial_title, event_generator()

    def _score_documents_by_intent(self, documents: List[Document], intents: List[str]) -> List[Tuple[Document, float]]:
        """
        根据意图对文档进行评分

        Args:
            documents: 待评分的文档列表
            intents: 意图列表

        Returns:
            List[Tuple[Document, float]]: 文档和评分的元组列表
        """
        if not documents:
            return []

        if not intents:
            # 如果没有意图，保持原始顺序和评分
            return [(doc, 1.0) for doc in documents]

        scored_docs = []

        for doc in documents:
            # 基础分数，保留原始重排序的相对顺序
            base_score = 1.0
            # 从元数据中获取重排序分数（如果有）
            if "rerank_score" in doc.metadata:
                base_score = doc.metadata["rerank_score"]

            # 意图相关加分
            intent_score = 0.0

            # 原版Minecraft查询的评分调整
            if "find_vanilla_wiki" in intents and "find_mod_info" not in intents:
                # 检查是否包含模组相关关键词
                mod_keywords = ["模组", "mod", "forge", "fabric", "mekanism", "tinkers"]
                if any(mod_keyword in doc.page_content.lower() for mod_keyword in mod_keywords):
                    # 包含模组关键词，降低评分但不完全排除
                    intent_score -= 0.5
                    logger.debug(f"文档包含模组关键词，评分-0.5")

            # 教程查询的评分调整
            if "find_tutorial" in intents:
                tutorial_keywords = ["步骤", "教程", "指南", "如何", "方法", "首先", "然后", "接着", "最后"]
                # 计算包含的教程关键词数量
                tutorial_keyword_count = sum(1 for keyword in tutorial_keywords if keyword in doc.page_content)
                if tutorial_keyword_count > 0:
                    # 根据关键词数量加分，最多加0.5分
                    tutorial_score = min(0.1 * tutorial_keyword_count, 0.5)
                    intent_score += tutorial_score
                    logger.debug(f"文档包含{tutorial_keyword_count}个教程关键词，评分+{tutorial_score:.1f}")

            # 合成配方查询的评分调整
            if "find_crafting_recipe" in intents:
                recipe_keywords = ["合成", "配方", "材料", "制作", "工作台", "熔炉"]
                # 计算包含的合成关键词数量
                recipe_keyword_count = sum(1 for keyword in recipe_keywords if keyword in doc.page_content)
                if recipe_keyword_count > 0:
                    # 根据关键词数量加分，最多加0.5分
                    recipe_score = min(0.1 * recipe_keyword_count, 0.5)
                    intent_score += recipe_score
                    logger.debug(f"文档包含{recipe_keyword_count}个合成关键词，评分+{recipe_score:.1f}")

            # 物品查询的评分调整
            if "query_item" in intents:
                item_keywords = ["物品", "方块", "工具", "武器", "装备", "属性", "效果", "用途"]
                # 计算包含的物品关键词数量
                item_keyword_count = sum(1 for keyword in item_keywords if keyword in doc.page_content)
                if item_keyword_count > 0:
                    # 根据关键词数量加分，最多加0.4分
                    item_score = min(0.1 * item_keyword_count, 0.4)
                    intent_score += item_score
                    logger.debug(f"文档包含{item_keyword_count}个物品关键词，评分+{item_score:.1f}")

            # 模组信息查询的评分调整
            if "find_mod_info" in intents:
                mod_info_keywords = ["模组", "mod", "版本", "更新", "作者", "功能", "特性"]
                # 计算包含的模组信息关键词数量
                mod_info_keyword_count = sum(1 for keyword in mod_info_keywords if keyword in doc.page_content.lower())
                if mod_info_keyword_count > 0:
                    # 根据关键词数量加分，最多加0.4分
                    mod_info_score = min(0.1 * mod_info_keyword_count, 0.4)
                    intent_score += mod_info_score
                    logger.debug(f"文档包含{mod_info_keyword_count}个模组信息关键词，评分+{mod_info_score:.1f}")

            # 综合回答的评分调整
            if "comprehensive_answer" in intents:
                # 对于综合回答，更长的文档可能包含更多信息
                length_score = min(len(doc.page_content) / 2000, 0.3)  # 最多加0.3分
                intent_score += length_score
                logger.debug(f"文档长度评分+{length_score:.1f}")

            # 计算最终评分
            final_score = base_score + intent_score
            scored_docs.append((doc, final_score))

            # 记录评分详情（仅在调试级别）
            logger.debug(f"文档评分 | 基础: {base_score:.2f} | 意图调整: {intent_score:+.2f} | 最终: {final_score:.2f}")

        return scored_docs

    def __del__(self):
        """
        析构函数，确保线程池被正确关闭
        """
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=False)
            logger.info("RAG Pipeline 线程池已关闭。")


rag\src\rag\rag_pipeline\query_enhancer.py
"""
查询增强模块

此模块提供了查询增强功能，用于提高检索的召回率。
"""

import time
from typing import Optional
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import HumanMessage

# 使用统一的日志配置
from ..logging_config import get_logger
from .. import config

logger = get_logger("query_enhancer")

class QueryEnhancer:
    """
    查询增强器，用于提高检索的召回率
    
    使用LLM生成更丰富的搜索表达，提高检索相关文档的能力。
    """
    
    def __init__(self, llm: BaseChatModel, expansion_prompt_template_str: str):
        """
        初始化查询增强器
        
        Args:
            llm: 用于查询扩展的语言模型
            expansion_prompt_template_str: 查询扩展提示模板
        """
        self.llm = llm
        self.prompt_template = expansion_prompt_template_str
        self.enabled = config.QUERY_EXPANSION_ENABLED
        
        if self.enabled:
            logger.info("查询增强器已启用")
        else:
            logger.info("查询增强器已禁用")
    
    async def expand_query(self, original_query: str) -> str:
        """
        扩展用户查询，生成更优化的搜索查询
        
        Args:
            original_query: 用户原始查询
            
        Returns:
            str: 扩展后的查询
        """
        # 如果查询增强被禁用，直接返回原始查询
        if not self.enabled:
            logger.debug("查询增强已禁用，使用原始查询")
            return original_query
            
        # 如果查询为空，直接返回
        if not original_query or not original_query.strip():
            logger.warning("查询为空，无法进行扩展")
            return original_query
        
        # 记录开始时间
        start_time = time.time()
        logger.info(f"开始扩展查询: '{original_query[:50]}{'...' if len(original_query) > 50 else ''}'")
        
        try:
            # 格式化提示
            formatted_prompt = self.prompt_template.format(original_query=original_query)
            
            # 调用LLM
            messages = [HumanMessage(content=formatted_prompt)]
            response = await self.llm.ainvoke(
                messages,
                temperature=config.QUERY_EXPANSION_TEMPERATURE
            )
            enhanced_query = response.content.strip()
            
            # 清理响应
            if "优化后的搜索查询:" in enhanced_query:
                enhanced_query = enhanced_query.split("优化后的搜索查询:")[-1].strip()
                
            if not enhanced_query:
                logger.warning(f"LLM返回空查询扩展结果，使用原始查询: '{original_query}'")
                return original_query
            
            # 记录扩展时间和结果
            expansion_time = time.time() - start_time
            logger.info(f"查询扩展完成，耗时: {expansion_time:.2f}秒")
            logger.info(f"原始查询: '{original_query}'")
            logger.info(f"扩展查询: '{enhanced_query}'")
            
            return enhanced_query
            
        except Exception as e:
            logger.error(f"查询扩展失败: {e}", exc_info=True)
            return original_query  # 出错时返回原始查询


rag\src\rag\rag_pipeline\reranker.py
"""
重排序模块

此模块提供了文档重排序功能，用于提高检索结果的相关性。
"""

import os
import logging
from typing import List, Dict, Any, Optional, Tuple
import time
from pathlib import Path
from langchain_core.documents import Document

# 使用统一的日志配置
from ..logging_config import get_logger
from .. import config

logger = get_logger("reranker")

class Reranker:
    """
    文档重排序器，用于提高检索结果的相关性

    使用交叉编码器模型对文档进行重排序，提高与查询的相关性。
    """

    def __init__(self, model_name: str = config.RERANK_MODEL_NAME, device_str: str = config.DEVICE):
        """
        初始化重排序器

        Args:
            model_name: 重排序模型名称或路径
            device_str: 设备类型 ('cpu' 或 'cuda')
        """
        self.model_name = model_name
        self.device = device_str
        self.tokenizer = None
        self.model = None

        # 检查模型路径
        self._resolve_model_path()

        # 初始化模型
        self._initialize_model()

    def _resolve_model_path(self):
        """解析模型路径，支持本地路径或模型名称"""
        # 检查模型名称是否是本地路径
        if os.path.exists(self.model_name):
            logger.info(f"使用本地重排序模型路径: {self.model_name}")
            return

        # 检查相对于当前文件的路径
        local_model_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                                       "models", os.path.basename(self.model_name))
        if os.path.exists(local_model_path):
            logger.info(f"在 {local_model_path} 找到重排序模型")
            self.model_name = local_model_path
            return

        # 检查项目根目录下的models文件夹
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        root_model_path = os.path.join(project_root, "models", os.path.basename(self.model_name))
        if os.path.exists(root_model_path):
            logger.info(f"在项目根目录下找到重排序模型: {root_model_path}")
            self.model_name = root_model_path
            return

        # 如果本地没有找到，将使用模型名称从HuggingFace下载
        logger.info(f"未找到本地重排序模型，将直接使用模型名称 {self.model_name} 从HuggingFace下载")

    def _initialize_model(self):
        """初始化重排序模型"""
        try:
            # 记录开始时间
            start_time = time.time()
            logger.info(f"开始初始化重排序模型: {self.model_name}，设备: {self.device}")

            # 导入必要的库
            try:
                from transformers import AutoModelForSequenceClassification, AutoTokenizer
                import torch
            except ImportError:
                logger.error("未安装必要的库: transformers 或 torch，请使用 pip install transformers torch 安装")
                logger.warning("将使用基于文档长度的简单排序作为回退策略")
                return

            # 加载模型和分词器
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)

                # 设置设备
                self.device = torch.device(self.device if torch.cuda.is_available() and "cuda" in self.device else "cpu")

                # 根据设备类型选择加载方式
                if self.device.type == "cuda":
                    # 在GPU上使用半精度加载模型
                    try:
                        logger.info(f"GPU环境: 尝试使用半精度(FP16)加载模型: {self.model_name}...")
                        self.model = AutoModelForSequenceClassification.from_pretrained(
                            self.model_name,
                            torch_dtype=torch.float16
                        )
                        logger.info("成功使用半精度加载模型")
                    except Exception as fp16_error:
                        logger.warning(f"半精度加载失败: {fp16_error}，使用标准精度")
                        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
                else:
                    # 在CPU上使用标准精度加载模型
                    logger.info(f"CPU环境: 使用标准精度加载模型: {self.model_name}...")
                    self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)

                # 将模型移动到设备
                self.model.to(self.device)
                logger.info(f"模型已加载到设备: {self.device}")

                # 确保模型处于评估模式
                self.model.eval()

                # 简单预热模型
                try:
                    logger.info("预热模型以提高首次推理速度...")
                    with torch.no_grad():
                        # 创建一个小批量的假数据进行预热
                        dummy_input = self.tokenizer(
                            [("预热查询", "预热文档")],
                            padding=True,
                            truncation=True,
                            return_tensors='pt',
                            max_length=64
                        ).to(self.device)
                        _ = self.model(**dummy_input)
                    logger.info("模型预热完成")
                except Exception as warmup_error:
                    logger.warning(f"模型预热失败: {warmup_error}，跳过预热步骤")

                # 记录初始化时间
                init_time = time.time() - start_time
                logger.info(f"重排序模型初始化完成，耗时: {init_time:.2f}秒，使用设备: {self.device}")
            except Exception as model_error:
                logger.error(f"加载重排序模型失败: {model_error}", exc_info=True)
                logger.warning("将使用基于文档长度的简单排序作为回退策略")
                self.tokenizer = None
                self.model = None

        except Exception as e:
            logger.error(f"初始化重排序模型失败: {e}", exc_info=True)
            logger.warning("将使用基于文档长度的简单排序作为回退策略")

    async def rerank_documents(self, query: str, documents: List[Document]) -> List[Document]:
        """
        对文档列表进行重排序，提高与查询的相关性

        Args:
            query: 用户查询
            documents: 待重排序的文档列表

        Returns:
            List[Document]: 重排序后的文档列表
        """
        if not documents:
            logger.warning("无文档可供重排序")
            return documents

        # 记录开始时间
        start_time = time.time()
        logger.info(f"开始重排序 {len(documents)} 个文档，查询: '{query[:30]}{'...' if len(query) > 30 else ''}'")

        try:
            # 如果模型已加载，使用模型进行重排序
            if self.model and self.tokenizer:
                try:
                    # 导入必要的库
                    import torch
                    import asyncio
                    from concurrent.futures import ThreadPoolExecutor
                    import numpy as np

                    
                    # 使用配置的批处理大小
                    batch_size = config.RERANK_BATCH_SIZE  # 可以通过环境变量调整

                    # 准备查询-文档对
                    pairs = []
                    for doc in documents:
                        # 限制文档内容长度，避免超出模型最大长度限制
                        doc_content = doc.page_content[:1024]
                        pairs.append((query, doc_content))

                    # 创建一个线程池执行器，利用多核CPU
                    import os
                    # 使用CPU核心数的一半作为线程数，但至少2个，最多4个
                    cpu_count = os.cpu_count() or 2
                    max_workers = max(2, min(cpu_count // 2, 4))
                    logger.info(f"使用 {max_workers} 个线程进行并行处理")
                    executor = ThreadPoolExecutor(max_workers=max_workers)
                    loop = asyncio.get_event_loop()

                    # 定义批处理推理函数
                    def process_batch(batch_pairs):
                        with torch.no_grad():
                            # 简化的动态最大长度计算
                            # 根据查询和文档长度估算所需的最大长度
                            query_len = len(batch_pairs[0][0])  # 所有对中查询都相同
                            max_doc_len = max(len(pair[1]) for pair in batch_pairs)

                            # 估算token数量 (每个字符约1.5个token)
                            estimated_tokens = int((query_len + max_doc_len) * 1.5)

                            # 设置动态最大长度，但限制在合理范围内
                            dynamic_max_length = min(512, max(128, min(estimated_tokens, 384)))

                            # 对批次进行编码
                            batch_inputs = self.tokenizer(
                                batch_pairs,
                                padding=True,
                                truncation=True,
                                return_tensors='pt',
                                max_length=dynamic_max_length
                            ).to(self.device)

                            # 执行推理
                            batch_outputs = self.model(**batch_inputs)

                            # 提取得分
                            if hasattr(batch_outputs, 'logits'):
                                batch_scores = batch_outputs.logits.squeeze(-1).cpu().numpy()
                            else:
                                batch_scores = batch_outputs[0].squeeze(-1).cpu().numpy()

                            # 确保返回的是一维数组
                            if len(batch_scores.shape) == 0:
                                batch_scores = np.array([float(batch_scores)])

                            return batch_scores

                    # 分批处理所有文档
                    all_scores = []
                    total_batches = (len(pairs) + batch_size - 1) // batch_size

                    # 如果文档数量少，直接处理
                    if len(pairs) <= batch_size:
                        logger.info(f"文档数量较少 ({len(pairs)}), 单批次处理")
                        batch_scores = await loop.run_in_executor(executor, process_batch, pairs)
                        all_scores = batch_scores.tolist()
                    else:
                        # 分批处理
                        logger.info(f"文档数量较多 ({len(pairs)}), 分 {total_batches} 批处理")
                        for i in range(0, len(pairs), batch_size):
                            batch_start_time = time.time()
                            batch_pairs = pairs[i:i+batch_size]
                            current_batch = (i // batch_size) + 1

                            logger.info(f"处理批次 {current_batch}/{total_batches}, 大小: {len(batch_pairs)}")
                            batch_scores = await loop.run_in_executor(executor, process_batch, batch_pairs)

                            all_scores.extend(batch_scores.tolist())
                            batch_time = time.time() - batch_start_time
                            logger.info(f"批次 {current_batch}/{total_batches} 完成, 耗时: {batch_time:.2f}秒")

                    # 关闭线程池
                    executor.shutdown(wait=False)

                    if len(all_scores) != len(documents):
                        logger.warning(f"得分数量 ({len(all_scores)}) 与过滤后文档数量 ({len(documents)}) 不匹配，使用回退策略")
                        return self._mock_rerank_by_length(documents)

                    # 按得分降序排序
                    scored_docs = sorted(zip(documents, all_scores), key=lambda x: x[1], reverse=True)

                    # 记录得分分布情况
                    if scored_docs:
                        scores_array = np.array([score for _, score in scored_docs])
                        top_score = scored_docs[0][1]
                        min_score = scored_docs[-1][1]
                        mean_score = np.mean(scores_array)
                        median_score = np.median(scores_array)
                        logger.info(f"得分统计 | 最高: {top_score:.4f} | 最低: {min_score:.4f} | 平均: {mean_score:.4f} | 中位数: {median_score:.4f}")

                    # 选取前K个文档
                    reranked_docs = [doc for doc, _ in scored_docs[:config.RERANK_TOP_K]]

                    # 记录重排序时间
                    rerank_time = time.time() - start_time
                    logger.info(f"模型重排序完成，耗时: {rerank_time:.2f}秒，选取了 {len(reranked_docs)}/{len(documents)} 个文档")

                    # 记录每个选中文档的得分
                    if logger.isEnabledFor(logging.DEBUG):
                        for i, (doc, score) in enumerate(scored_docs[:config.RERANK_TOP_K]):
                            doc_title = getattr(doc.metadata, 'title', None) or doc.page_content[:30]
                            logger.debug(f"Top {i+1}: 得分={score:.4f}, 文档='{doc_title}...'")

                    return reranked_docs

                except Exception as rerank_error:
                    logger.error(f"使用模型重排序时发生错误: {rerank_error}", exc_info=True)
                    logger.warning("由于重排序错误，使用基于文档长度的简单排序作为回退")
                    reranked_docs = self._mock_rerank_by_length(documents)
            else:
                # 模型未加载，使用模拟实现
                logger.warning("重排序模型未加载，使用基于文档长度的简单排序")
                reranked_docs = self._mock_rerank_by_length(documents)

            # 记录重排序时间
            rerank_time = time.time() - start_time
            logger.info(f"重排序完成，耗时: {rerank_time:.2f}秒，选取了 {len(reranked_docs)} 个文档")

            return reranked_docs

        except Exception as e:
            logger.error(f"重排序过程中发生错误: {e}", exc_info=True)

            # 出错时使用回退策略
            logger.warning("由于重排序错误，使用基于文档长度的简单排序作为回退")
            fallback_docs = self._mock_rerank_by_length(documents)
            return fallback_docs

    def _mock_rerank_by_length(self, documents: List[Document]) -> List[Document]:
        """
        简单的基于文档长度的排序，作为重排序失败时的回退策略

        Args:
            documents: 待排序的文档列表

        Returns:
            List[Document]: 排序后的文档列表
        """
        # 按文档内容长度降序排序
        sorted_docs = sorted(documents, key=lambda d: len(d.page_content), reverse=True)

        # 选取前K个文档
        top_k = min(len(sorted_docs), config.RERANK_TOP_K)
        result = sorted_docs[:top_k]

        logger.info(f"使用基于长度的简单排序，选取了前 {top_k} 个文档")
        return result


rag\src\rag\rag_pipeline\__init__.py
"""
RAG Pipeline模块

此模块提供了RAG (Retrieval-Augmented Generation) 流程的核心组件，
包括检索、过滤、上下文整合、Prompt组装、LLM调用等步骤。
"""

from .pipeline import RAGPipeline

__all__ = ["RAGPipeline"]


rag\src\rag\rag_pipeline\intent_processing\classifier.py
"""
意图分类器模块

此模块提供了意图分类器的实现，用于从用户查询中识别意图。
"""

import json
import re
import time
from typing import List
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI

from ...prompts import INTENT_CLASSIFICATION_PROMPT_TEMPLATE
from ...logging_config import get_logger

# 使用统一的日志配置
logger = get_logger("intent_classifier")

class IntentClassifier:
    """
    意图分类器，用于从用户查询中识别意图

    能够识别多个意图，并以JSON格式返回结果。
    """

    def __init__(self, llm: ChatOpenAI):
        """
        初始化意图分类器

        Args:
            llm: 用于意图分类的语言模型
        """
        self.llm = llm

    async def classify_intent(self, query: str) -> List[str]:
        """
        从用户查询中识别意图

        Args:
            query: 用户查询

        Returns:
            List[str]: 识别出的意图列表
        """
        # 记录开始时间
        start_time = time.time()

        # 使用提示模板格式化查询
        prompt = INTENT_CLASSIFICATION_PROMPT_TEMPLATE.format(query=query)

        try:
            # 调用LLM进行意图分类
            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            response_text = response.content if hasattr(response, 'content') else str(response)

            # 从响应中提取JSON
            # 首先尝试匹配对象格式 {"intents": [...]}
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    intents = result.get("intents", [])

                    # 记录耗时
                    classification_time = time.time() - start_time
                    logger.info(f"意图分类耗时: {classification_time:.2f}秒，识别出的意图: {intents}")

                    return intents
                except json.JSONDecodeError:
                    logger.warning(f"JSON对象解析失败: {json_match.group()}")

            # 如果对象格式匹配失败，尝试匹配数组格式 [...]
            array_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if array_match:
                try:
                    intents = json.loads(array_match.group())
                    if isinstance(intents, list):
                        # 记录耗时
                        classification_time = time.time() - start_time
                        logger.info(f"意图分类耗时: {classification_time:.2f}秒，识别出的意图(数组格式): {intents}")

                        return intents
                except json.JSONDecodeError:
                    logger.warning(f"JSON数组解析失败: {array_match.group()}")

            # 如果所有尝试都失败
            logger.warning(f"无法从响应中提取JSON: {response_text}")
            return ["chit_chat"]  # 默认返回闲聊意图

        except Exception as e:
            logger.error(f"意图分类失败: {e}")
            return ["chit_chat"]  # 出错时默认返回闲聊意图


rag\src\rag\rag_pipeline\intent_processing\__init__.py
"""
意图处理模块

此模块包含与意图处理相关的组件，如意图分类器。
"""

from .classifier import IntentClassifier

__all__ = [
    "IntentClassifier",
]


rag\src\rag\rag_pipeline\processors\filters.py
"""
文档过滤器模块

此模块提供了用于过滤和处理检索到的文档的工具。
"""

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_transformers import EmbeddingsRedundantFilter
from typing import List, Optional
from langchain_core.documents import Document

class DocumentFilterManager:
    """
    文档过滤器管理器，用于创建和应用文档过滤器
    """
    
    @staticmethod
    def create_redundant_filter(
        embeddings: HuggingFaceEmbeddings,
        similarity_threshold: float = 0.9
    ) -> EmbeddingsRedundantFilter:
        """
        创建冗余过滤器
        
        Args:
            embeddings: 嵌入模型
            similarity_threshold: 相似度阈值，默认为0.95
            
        Returns:
            EmbeddingsRedundantFilter: 冗余过滤器
        """
        return EmbeddingsRedundantFilter(
            embeddings=embeddings,
            similarity_threshold=similarity_threshold
        )
    
    @staticmethod
    def filter_by_score(
        documents: List[Document],
        score_key: str = "metadata_match_score",
        min_score: float = 0.0,
        max_docs: Optional[int] = None
    ) -> List[Document]:
        """
        根据分数过滤文档
        
        Args:
            documents: 文档列表
            score_key: 分数键名，默认为"metadata_match_score"
            min_score: 最小分数，默认为0.0
            max_docs: 最大文档数量，默认为None（不限制）
            
        Returns:
            List[Document]: 过滤后的文档列表
        """
        # 过滤分数大于等于min_score的文档
        filtered_docs = [
            doc for doc in documents 
            if score_key in doc.metadata and doc.metadata[score_key] >= min_score
        ]
        
        # 按分数降序排序
        sorted_docs = sorted(
            filtered_docs,
            key=lambda doc: doc.metadata.get(score_key, 0),
            reverse=True
        )
        
        # 限制文档数量
        if max_docs is not None:
            return sorted_docs[:max_docs]
        
        return sorted_docs
    
    @staticmethod
    def filter_by_source(
        documents: List[Document],
        source_name: str,
        source_key: str = "retriever_source"
    ) -> List[Document]:
        """
        根据来源过滤文档
        
        Args:
            documents: 文档列表
            source_name: 来源名称
            source_key: 来源键名，默认为"retriever_source"
            
        Returns:
            List[Document]: 过滤后的文档列表
        """
        filtered_docs = []
        for doc in documents:
            if source_key in doc.metadata:
                sources = doc.metadata[source_key]
                if isinstance(sources, list) and source_name in sources:
                    filtered_docs.append(doc)
                elif sources == source_name:
                    filtered_docs.append(doc)
        
        return filtered_docs


rag\src\rag\rag_pipeline\processors\__init__.py
"""
处理器模块

此模块包含各种文档处理器，用于过滤、转换和增强检索到的文档。
"""

from .filters import DocumentFilterManager

__all__ = ["DocumentFilterManager"]


rag\src\rag\rag_pipeline\retrievers\factory.py
"""
检索器工厂模块

此模块提供了创建和组合检索器的工厂类。
"""

from langchain_core.documents import Document
from langchain_openai import ChatOpenAI # 将用于类型提示，但实际传入可能是 BaseChatModel
from langchain_core.language_models.chat_models import BaseChatModel # 导入 BaseChatModel
from langchain.retrievers import EnsembleRetriever
from langchain_chroma import Chroma
from typing import List, Optional, Dict, Any
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun
# Document 已在上面导入

import logging # 添加日志记录
logger = logging.getLogger(__name__) # 获取 logger 实例

from .metadata_matching import MetadataMatchingRetriever
from .sourced import SourcedRetriever
from .specialized_retrievers import TutorialKeywordRetriever, GenericDenseRetriever # 导入新类

# 旧的 KeywordTutorialFilterRetriever 类已移除，逻辑移至 TutorialKeywordRetriever
class RetrieverFactory:
    """
    检索器工厂类，用于创建和组合检索器
    """

    def __init__(
        self,
        vector_db: Chroma,
        documents: List[Document],
        metadata_llm: BaseChatModel, # 使用 BaseChatModel
        k: int
    ):
        """
        初始化 RetrieverFactory。

        参数:
            vector_db: Chroma 向量数据库实例。
            documents: 用于元数据匹配的文档列表。
            metadata_llm: 用于元数据匹配的语言模型。
            k: 检索器返回的最大文档数量。
        """
        self.vector_db = vector_db
        self.documents = documents
        self.metadata_llm = metadata_llm
        self.k = k
        logger.info(f"RetrieverFactory 初始化完成，k={self.k}")

    # 改为实例方法
    def create_ensemble_retriever(
        self,
        weights: Optional[List[float]] = None
    ) -> EnsembleRetriever:
        """
        使用实例属性创建集成检索器 (EnsembleRetriever)。

        参数:
            weights: (可选) 检索器的权重列表，默认为 [0.5, 0.5]。

        返回:
            EnsembleRetriever: 配置好的集成检索器。
        """
        # 创建密集检索器 (注意: EnsembleRetriever 内部的检索器 k 值由 self.k 控制)
        dense_retriever = self.vector_db.as_retriever(
            search_type="mmr",
            search_kwargs={
                "k": self.k, # 使用 self.k 或特定值
                "fetch_k": 20,
                "lambda_mult": 0.5
            }
        )
        sourced_dense_retriever = SourcedRetriever(dense_retriever, "dense_compression")

        # 创建元数据匹配检索器
        metadata_matching_retriever = MetadataMatchingRetriever(self.documents, self.metadata_llm, k=self.k)
        sourced_metadata_retriever = SourcedRetriever(metadata_matching_retriever, "metadata_matching")

        # 设置默认权重
        if weights is None:
            weights = [0.5, 0.5]

        # 创建集成检索器
        return EnsembleRetriever(
            retrievers=[sourced_dense_retriever, sourced_metadata_retriever],
            weights=weights
        )

    # 改为实例方法
    def create_dense_retriever(self) -> SourcedRetriever:
        """
        使用实例属性 vector_db 和 k 创建密集检索器。

        返回:
            SourcedRetriever: 包装了密集检索器的 SourcedRetriever 实例。
        """
        dense_retriever = self.vector_db.as_retriever(
            search_type="mmr",
            search_kwargs={
                "k": self.k,
                "fetch_k": 20,
                "lambda_mult": 0.5
            }
        )
        return SourcedRetriever(dense_retriever, "dense_compression")

    # 改为实例方法
    def create_metadata_matching_retriever(self) -> SourcedRetriever:
        """
        使用实例属性创建元数据匹配检索器。

        返回:
            SourcedRetriever: 包装了元数据匹配检索器的 SourcedRetriever 实例。
        """
        metadata_matching_retriever = MetadataMatchingRetriever(self.documents, self.metadata_llm, k=self.k)
        return SourcedRetriever(metadata_matching_retriever, "metadata_matching")

    # 改为实例方法
    def get_retrievers_by_intent(
        self,
        intents: List[str]
    ) -> List[SourcedRetriever]:
        """
        根据提供的意图获取 SourcedRetriever 实例列表。
        使用实例属性 (vector_db, documents, metadata_llm, k) 创建检索器。

        Args:
            intents: 意图标签列表。

        Returns:
            List[SourcedRetriever]: 对应有效意图的 SourcedRetriever 实例列表。
        """
        retrievers: List[SourcedRetriever] = []
        processed_intents = set() # 跟踪已处理的意图，避免重复

        # --- 意图到检索器的映射 ---
        for intent in intents:
            if intent in processed_intents or intent == "chit_chat":
                logger.debug(f"跳过意图: {intent} (已处理或为闲聊)")
                continue

            base_retriever: Optional[BaseRetriever] = None
            source_name: Optional[str] = None

            logger.debug(f"处理意图: {intent}")

            if intent == "query_item":
                base_retriever = MetadataMatchingRetriever(documents=self.documents, llm=self.metadata_llm, k=self.k)
                source_name = "metadata_query_item"
            elif intent == "find_mod_info":
                base_retriever = MetadataMatchingRetriever(documents=self.documents, llm=self.metadata_llm, k=self.k)
                source_name = "metadata_find_mod_info"
            elif intent == "find_tutorial":
                base_retriever = TutorialKeywordRetriever(vector_db=self.vector_db, k=self.k)
                source_name = "tutorial_keyword"
            elif intent == "find_vanilla_wiki":
                logger.warning(f"意图 '{intent}' 使用通用密集检索器作为回退。")
                base_retriever = GenericDenseRetriever(vector_db=self.vector_db, k=self.k)
                source_name = "dense_fallback_vanilla_wiki"
            elif intent == "comprehensive_answer":
                base_retriever = GenericDenseRetriever(vector_db=self.vector_db, k=self.k)
                source_name = "dense_comprehensive"
            # 处理 find_crafting_recipe (之前是占位符，现在也用后备)
            elif intent == "find_crafting_recipe":
                 logger.warning(f"意图 '{intent}' 未被特别处理，使用通用密集检索器作为回退。")
                 base_retriever = GenericDenseRetriever(vector_db=self.vector_db, k=self.k)
                 source_name = "dense_fallback_crafting_recipe"
            else:
                # 处理未知意图
                logger.warning(f"遇到未知意图 '{intent}'。使用通用密集检索器作为回退。")
                base_retriever = GenericDenseRetriever(vector_db=self.vector_db, k=self.k)
                source_name = f"dense_fallback_unknown_{intent}" # 保证 source_name 唯一性

            if base_retriever and source_name:
                logger.debug(f"意图 '{intent}' 映射到检索器 '{source_name}'")
                # 传递意图信息给 SourcedRetriever
                sourced_retriever = SourcedRetriever(base_retriever, source_name, intent=intent)
                retrievers.append(sourced_retriever)
                processed_intents.add(intent)
            else:
                 logger.warning(f"意图 '{intent}' 未能成功创建检索器实例。")


        # --- 处理无有效检索器或无意图的情况 ---
        # 检查是否提供了非闲聊意图
        has_non_chit_chat_intent = any(i != "chit_chat" for i in intents)

        if not retrievers and intents and has_non_chit_chat_intent:
            # 提供了非闲聊意图，但未能创建任何特定检索器
            logger.warning("未能为提供的意图成功创建任何特定检索器。返回通用密集检索器作为回退。")
            fallback_retriever = GenericDenseRetriever(vector_db=self.vector_db, k=self.k)
            # 使用第一个非闲聊意图作为回退检索器的意图
            fallback_intent = next((i for i in intents if i != "chit_chat"), "未知意图")
            sourced_fallback = SourcedRetriever(fallback_retriever, "dense_fallback_default", intent=fallback_intent)
            retrievers.append(sourced_fallback)
        elif not intents:
            # 未提供意图，返回默认的通用检索器
            logger.warning("未提供意图。返回通用密集检索器作为默认。")
            default_retriever = GenericDenseRetriever(vector_db=self.vector_db, k=self.k)
            # 使用统一的 'default' 标签，并设置默认意图
            sourced_default = SourcedRetriever(default_retriever, "dense_fallback_default", intent="综合查询")
            retrievers.append(sourced_default)
        # (如果只有 chit_chat 意图，或 fallback 已处理，则流程继续)

        # 记录最终选择的检索器
        selected_retriever_names = [r.source_name for r in retrievers] # SourcedRetriever 保证有 source_name

        logger.info(f"RetrieverFactory: 输入意图 {intents}。最终选择的检索器名称: {selected_retriever_names}")

        return retrievers


rag\src\rag\rag_pipeline\retrievers\metadata_matching.py
"""
元数据匹配检索器

此模块提供了一个专门为Minecraft模组领域设计的检索器，
能够从用户查询中提取模组名称和物品名称，并根据元数据匹配为文档评分。
"""

from langchain_core.runnables.base import Runnable
from langchain_core.messages import HumanMessage
import json
import re
from ...prompts import METADATA_MATCHING_PROMPT_TEMPLATE
from ...logging_config import get_logger

# 使用统一的日志配置
logger = get_logger("metadata_matching")

class MetadataMatchingRetriever(Runnable):
    """
    元数据匹配检索器，专为Minecraft模组领域设计

    能够从用户查询中提取模组名称和物品名称，并根据元数据匹配为文档评分。
    当无匹配时提供关键词回退机制。
    """

    def __init__(self, documents, llm, k=4):
        """
        初始化元数据匹配检索器

        Args:
            documents: 文档列表
            llm: 用于提取实体的语言模型
            k: 返回的最大文档数量
        """
        self.documents = documents
        self.llm = llm
        self.k = k

        self.mod_names = set()
        self.item_names = set()
        for doc in documents:
            if "模组名称" in doc.metadata:
                self.mod_names.add(doc.metadata["模组名称"].lower())
            if "物品名称" in doc.metadata:
                self.item_names.add(doc.metadata["物品名称"].lower())

    def _normalize_name(self, name):
        """
        标准化名称，移除括号内容并转为小写

        Args:
            name: 要标准化的名称

        Returns:
            str: 标准化后的名称
        """
        if '(' in name and ')' in name:
            last_open = name.rfind('(')
            if last_open > -1 and ')' in name[last_open:]:
                name = name[:last_open].strip()
        return name.lower()

    def _extract_entities(self, query):
        """
        从查询中提取模组名称和物品名称

        Args:
            query: 用户查询

        Returns:
            dict: 包含提取的模组名称和物品名称的字典
        """
        # 使用从prompts模块导入的元数据匹配prompt模板
        prompt = METADATA_MATCHING_PROMPT_TEMPLATE.format(query=query)
        try:
            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            response_text = response.content if hasattr(response, 'content') else str(response)
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return {
                    "mod_names": [name.lower() for name in result.get("mod_names", [])],
                    "item_names": [name.lower() for name in result.get("item_names", [])]
                }
            else:
                logger.warning(f"无法从响应中提取JSON: {response_text}")
        except Exception as e:
            logger.error(f"实体提取失败: {e}")
            logger.error(f"LLM响应: {response if 'response' in locals() else '无响应'}")
        return {"mod_names": [], "item_names": []}

    def invoke(self, query, config=None, **kwargs):
        """
        执行检索

        Args:
            query: 用户查询
            config: 配置参数
            **kwargs: 其他参数

        Returns:
            list: 相关文档列表
        """
        logger.info(f"正在从查询中提取实体: {query}")
        entities = self._extract_entities(query)
        logger.info(f"提取的实体: {entities}")
        def score_document(doc):
            score = 0
            if "模组名称" in doc.metadata and entities["mod_names"]:
                doc_mod_name = self._normalize_name(doc.metadata["模组名称"])
                for mod_name in entities["mod_names"]:
                    if doc_mod_name in mod_name or mod_name in doc_mod_name:
                        score += 3
                        break

            if "物品名称" in doc.metadata and entities["item_names"]:
                doc_item_name = self._normalize_name(doc.metadata["物品名称"])
                for item_name in entities["item_names"]:
                    if doc_item_name == item_name:
                        score += 5
                        break
                    if doc_item_name in item_name or item_name in doc_item_name:
                        score += 2
                        break

            if doc.metadata.get("类型") == "模组主体" and score > 0:
                score += 1
            return score

        scored_docs = [(doc, score_document(doc)) for doc in self.documents]
        relevant_docs = [doc for doc, score in sorted(scored_docs, key=lambda x: x[1], reverse=True) if score > 0]

        if not relevant_docs:
            logger.info("元数据匹配没有找到文档，使用关键词匹配作为回退")
            query_lower = query.lower()
            fallback_docs = []
            for doc in self.documents:
                content_lower = doc.page_content.lower()
                if any(word in content_lower for word in query_lower.split() if len(word) > 1):
                    fallback_docs.append(doc)
            relevant_docs = fallback_docs[:self.k]

        logger.info(f"元数据匹配检索器找到了 {len(relevant_docs)} 个相关文档")
        for doc in relevant_docs:
            doc.metadata["metadata_match_score"] = score_document(doc)
        return relevant_docs[:self.k]

    def with_config(self, **kwargs):
        """配置检索器参数"""
        if "k" in kwargs:
            self.k = kwargs["k"]
        return self



rag\src\rag\rag_pipeline\retrievers\sourced.py
"""
来源标记检索器

此模块提供了一个检索器包装器，用于为检索结果添加来源标记。
"""

from langchain_core.runnables.base import Runnable

class SourcedRetriever(Runnable):
    """
    来源标记检索器，为检索结果添加来源标记的包装器

    用于跟踪文档的检索来源，在多种检索策略中标记文档来源。
    """

    def __init__(self, retriever, source_name, intent=None):
        """
        初始化来源标记检索器

        Args:
            retriever: 被包装的检索器
            source_name: 来源名称
            intent: 检索意图，用于标记文档是由哪个意图检索出来的
        """
        self.retriever = retriever
        self.source_name = source_name
        self.intent = intent

    def invoke(self, query, config=None, **kwargs):
        """
        执行检索并添加来源标记

        Args:
            query: 用户查询
            config: 配置参数
            **kwargs: 其他参数

        Returns:
            list: 添加了来源标记的文档列表
        """
        docs = self.retriever.invoke(query, config=config, **kwargs)
        for doc in docs:
            # 添加检索器来源
            if "retriever_source" in doc.metadata and isinstance(doc.metadata["retriever_source"], list):
                if self.source_name not in doc.metadata["retriever_source"]:
                    doc.metadata["retriever_source"].append(self.source_name)
            elif "retriever_source" in doc.metadata:
                doc.metadata["retriever_source"] = [doc.metadata["retriever_source"], self.source_name]
            else:
                doc.metadata["retriever_source"] = [self.source_name]

            # 添加检索意图
            if self.intent:
                doc.metadata["retrieved_by_intent"] = self.intent
            elif "retrieved_by_intent" not in doc.metadata:
                doc.metadata["retrieved_by_intent"] = "未知意图"
        return docs

    # 移除了 get_relevant_documents 方法，因为 invoke 方法已提供核心功能，
    # 且 RAGPipeline 优先使用 invoke/ainvoke。
    # 来源标记逻辑已在 invoke 方法中处理。

    def with_config(self, **kwargs):
        """传递配置到底层检索器"""
        self.retriever = self.retriever.with_config(**kwargs) if hasattr(self.retriever, 'with_config') else self.retriever
        return self

    def with_retry(self, **kwargs):
        """传递重试配置到底层检索器"""
        if hasattr(self.retriever, 'with_retry'):
            self.retriever = self.retriever.with_retry(**kwargs)
        return self

    def with_timeout(self, timeout, **kwargs):
        """传递超时配置到底层检索器"""
        if hasattr(self.retriever, 'with_timeout'):
            self.retriever = self.retriever.with_timeout(timeout, **kwargs)
        return self


rag\src\rag\rag_pipeline\retrievers\specialized_retrievers.py
# src/rag/rag_pipeline/retrievers/specialized_retrievers.py
from typing import List

from langchain_chroma import Chroma
from langchain_core.callbacks import CallbackManagerForRetrieverRun
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever


class TutorialKeywordRetriever(BaseRetriever):
    """
    一个专门用于检索教程相关文档的检索器。

    它首先使用基础向量存储进行密集检索，然后根据页面内容是否包含
    特定的教程相关关键词（如 "教程", "指南"）来过滤结果。
    """
    vector_db: Chroma
    k: int = 4
    keywords: List[str] = ["教程", "指南", "如何", "步骤", "方法", "教学", "入门", "进阶"] # 扩展了关键词

    def _get_relevant_documents(
        self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """
        获取与查询相关的教程文档。

        Args:
            query: 用户查询字符串。
            run_manager: LangChain 回调管理器。

        Returns:
            过滤后的相关文档列表。
        """
        # 增加初始检索数量，为后续过滤留出空间，但不超过一个较大的限制（例如 15）
        initial_k = min(self.k * 2, 15)
        base_retriever = self.vector_db.as_retriever(
            search_kwargs={'k': initial_k, 'filter': {'类型': '教程'}}
        )
        initial_docs = base_retriever.get_relevant_documents(query)

        # 过滤包含关键词的文档
        filtered_docs = [
            doc for doc in initial_docs
            if any(keyword in doc.page_content for keyword in self.keywords)
        ]

        # 返回最多 k 个文档
        return filtered_docs[:self.k]


class GenericDenseRetriever(BaseRetriever):
    """
    一个通用的密集检索器。

    它直接使用向量存储的 `as_retriever` 方法进行标准相似性搜索。
    """
    vector_db: Chroma
    k: int = 4

    def _get_relevant_documents(
        self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """
        获取与查询相关的文档。

        Args:
            query: 用户查询字符串。
            run_manager: LangChain 回调管理器。

        Returns:
            相关文档列表。
        """
        base_retriever = self.vector_db.as_retriever(
            search_kwargs={'k': self.k}
        )
        return base_retriever.get_relevant_documents(query)

rag\src\rag\rag_pipeline\retrievers\__init__.py
"""
检索器模块

此模块包含各种检索器实现，用于从文档集合中检索相关文档。
"""

from .metadata_matching import MetadataMatchingRetriever
from .sourced import SourcedRetriever
from .factory import RetrieverFactory

__all__ = ["MetadataMatchingRetriever", "SourcedRetriever", "RetrieverFactory"]


rag\src\rag\routes\auth.py
"""
认证 API 路由模块

此模块定义了与用户认证相关的 API 端点，
包括用户注册、登录和获取访问令牌等功能。
"""
from fastapi import APIRouter, Depends, HTTPException
from fastapi.security import OAuth2PasswordRequestForm
from pydantic import BaseModel
from typing import Optional
from ..dependencies import get_auth_service
from ..services.auth_service import AuthService


# 创建路由
router = APIRouter(prefix="/auth", tags=["auth"])

# 请求和响应模型
class UserRegister(BaseModel):
    username: str
    password: str
    email: str

class UserLogin(BaseModel):
    username: str
    password: str

class TokenResponse(BaseModel):
    success: bool
    message: str
    token: Optional[str] = None
    user_id: Optional[int] = None
    username: Optional[str] = None

class BasicResponse(BaseModel):
    success: bool
    message: str

# 注册路由
@router.post("/register", response_model=TokenResponse)
async def register(
    user_data: UserRegister,
    auth_service: AuthService = Depends(get_auth_service)
):
    # 使用服务层注册用户
    return await auth_service.register_user(
        username=user_data.username,
        email=user_data.email,
        password=user_data.password
    )

# 登录路由
@router.post("/login", response_model=TokenResponse)
async def login(
    user_data: UserLogin,
    auth_service: AuthService = Depends(get_auth_service)
):
    # 使用服务层登录用户
    return await auth_service.login_user(
        username=user_data.username,
        password=user_data.password
    )

# OAuth2兼容登录路由 (用于支持swagger UI)
@router.post("/token")
async def login_for_access_token(
    form_data: OAuth2PasswordRequestForm = Depends(),
    auth_service: AuthService = Depends(get_auth_service)
):
    try:
        # 使用服务层登录用户
        login_result = await auth_service.login_user(
            username=form_data.username,
            password=form_data.password
        )

        # 返回OAuth2兼容的响应格式
        return {"access_token": login_result["token"], "token_type": "bearer"}
    except HTTPException:
        # 重新抛出异常，保持与原始行为一致
        raise

rag\src\rag\routes\conversation.py
"""
对话 API 路由模块

此模块定义了与用户对话相关的 API 端点，
包括创建、获取、更新、删除对话，以及处理对话消息和流式响应。
"""
from fastapi import APIRouter, Depends, BackgroundTasks
from sse_starlette.sse import EventSourceResponse
from pydantic import BaseModel
from typing import List, AsyncIterable, Dict, Any
from datetime import datetime
import json

from ..database import User, SessionLocal
from ..dependencies import get_conversation_service, get_current_user, get_rag_pipeline
from ..services.conversation_service import ConversationService
from ..rag_pipeline.pipeline import RAGPipeline

# 创建路由
router = APIRouter(prefix="/conversations", tags=["conversations"])

# 请求和响应模型
class MessageCreate(BaseModel):
    content: str

class MessageResponse(BaseModel):
    id: int
    role: str
    content: str
    created_at: datetime

    class Config:
        from_attributes = True

class ConversationCreate(BaseModel):
    title: str

class ConversationUpdate(BaseModel):
    title: str

class ConversationResponse(BaseModel):
    id: int
    title: str
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

class ConversationDetailResponse(BaseModel):
    id: int
    title: str
    created_at: datetime
    updated_at: datetime
    messages: List[MessageResponse]

    class Config:
        from_attributes = True

class NewMessageRequest(BaseModel):
    message: str

class NewMessageResponse(BaseModel):
    conversation_id: int
    messages: List[MessageResponse]
    title: str

    class Config:
        from_attributes = True

# 创建新对话 (手动方式，保留旧有API但不在前端使用)
@router.post("", response_model=ConversationResponse)
async def create_conversation(
    conversation_data: ConversationCreate,
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    return await service.create_conversation(
        user_id=current_user.id,
        title=conversation_data.title
    )

# 获取用户的所有对话
@router.get("", response_model=List[ConversationResponse])
async def get_conversations(
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    return await service.get_user_conversations(user_id=current_user.id)

# 获取单个对话详情
@router.get("/{conversation_id}", response_model=ConversationDetailResponse)
async def get_conversation(
    conversation_id: int,
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    return await service.get_conversation(
        conversation_id=conversation_id,
        user_id=current_user.id
    )

# 更新对话标题
@router.put("/{conversation_id}", response_model=ConversationResponse)
async def update_conversation(
    conversation_id: int,
    conversation_data: ConversationUpdate,
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    return await service.update_conversation(
        conversation_id=conversation_id,
        user_id=current_user.id,
        title=conversation_data.title
    )

# 删除对话
@router.delete("/{conversation_id}")
async def delete_conversation(
    conversation_id: int,
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    await service.delete_conversation(
        conversation_id=conversation_id,
        user_id=current_user.id
    )
    return {"message": "对话已删除"}

# 后台任务：保存助手消息
async def save_assistant_message_task(conversation_id: int, assistant_content: str):
    """后台任务：保存完整的助手消息"""
    db = SessionLocal()  # 为后台任务创建新的数据库会话
    try:
        # 创建服务实例 (后台任务中不能使用Depends，需要手动创建服务实例)
        # 注意：在后台任务中，我们不需要RAG Pipeline，因为我们只是保存消息
        # 创建一个空的RAG Pipeline占位符
        dummy_pipeline = None
        service = ConversationService(
            db=db,
            rag_pipeline=dummy_pipeline,  # 这里不需要RAG Pipeline
        )
        await service.save_assistant_message(conversation_id, assistant_content)
    except Exception as e:
        print(f"后台任务错误：保存助手消息失败 (对话ID: {conversation_id}): {e}")
    finally:
        db.close()

# 后台任务：更新对话标题
async def update_conversation_title_task(conversation_id: int, title: str):
    """后台任务：更新对话标题"""
    db = SessionLocal()
    try:
        # 创建服务实例 (后台任务中不能使用Depends，需要手动创建服务实例)
        # 注意：在后台任务中，我们不需要RAG Pipeline，因为我们只是更新标题
        dummy_pipeline = None
        service = ConversationService(
            db=db,
            rag_pipeline=dummy_pipeline,  # 这里不需要RAG Pipeline
        )
        await service.update_conversation_title(conversation_id, title)
    except Exception as e:
        print(f"后台任务错误：更新标题失败 (对话ID: {conversation_id}): {e}")
    finally:
        db.close()

# 在对话中添加新消息并获取流式回复
@router.post("/{conversation_id}/messages")
async def stream_message(
    conversation_id: int,
    message_data: MessageCreate,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    # 使用服务层处理新消息
    async def event_generator() -> AsyncIterable[Dict[str, Any]]:
        full_response = ""
        async for event in service.handle_new_message(
            conversation_id=conversation_id,
            user_id=current_user.id,
            user_content=message_data.content
        ):
            # 如果是消息事件，累积完整响应内容
            if event["event"] == "message":
                full_response += event["data"]

            # 传递所有事件
            yield event

            # 如果是结束事件，安排后台任务保存助手消息
            if event["event"] == "end":
                background_tasks.add_task(save_assistant_message_task, conversation_id, full_response)
                print("已安排后台任务保存助手消息")

    return EventSourceResponse(event_generator())

# 新增：自动创建对话并获取流式回复
@router.post("/new")
async def stream_new_conversation(
    message_data: NewMessageRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user),
    service: ConversationService = Depends(get_conversation_service)
):
    try:
        # 使用服务层创建新对话并处理第一条消息
        conversation_id, _, event_generator_stream = await service.handle_new_conversation_message(
            user_id=current_user.id,
            user_content=message_data.message
        )

        # 包装事件生成器，在适当的时候添加后台任务
        async def wrapped_event_generator() -> AsyncIterable[Dict[str, Any]]:
            full_response = ""

            async for event in event_generator_stream:
                # 传递所有事件
                yield event

                # 根据事件类型执行不同操作
                if event["event"] == "message":
                    full_response += event["data"]
                elif event["event"] == "end":
                    # 流结束，安排保存助手消息的后台任务
                    background_tasks.add_task(save_assistant_message_task, conversation_id, full_response)
                    print("已安排后台任务保存助手消息")
                elif event["event"] == "title_update":
                    # 标题更新，解析新标题并安排更新标题的后台任务
                    title_data = json.loads(event["data"])
                    generated_title = title_data["title"]
                    background_tasks.add_task(update_conversation_title_task, conversation_id, generated_title)
                    print(f"已安排后台任务更新标题为: {generated_title}")

        return EventSourceResponse(wrapped_event_generator())

    except Exception as e:
        # 处理创建对话或保存用户消息时的初始错误
        print(f"创建对话或保存用户消息时出错: {e}")
        async def initial_error_stream():
            yield {"event": "error", "data": json.dumps({"message": "无法创建新对话"})}
        return EventSourceResponse(initial_error_stream())

rag\src\rag\routes\feedback.py
"""
反馈 API 路由模块

此模块定义了与用户反馈相关的 API 端点，
包括提交反馈、获取反馈列表（用户或管理员）以及更新反馈状态（管理员）。
"""
from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime
from ..database import User, FeedbackType, FeedbackStatus
from ..dependencies import get_feedback_service, get_current_user, is_admin
from ..services.feedback_service import FeedbackService

# 创建路由
router = APIRouter(prefix="/feedback", tags=["feedback"])

# 请求和响应模型
class FeedbackCreate(BaseModel):
    type: FeedbackType
    content: str

class FeedbackUpdate(BaseModel):
    status: Optional[FeedbackStatus] = None
    admin_response: Optional[str] = None

class FeedbackResponse(BaseModel):
    id: int
    type: str
    content: str
    status: str
    admin_response: Optional[str]
    created_at: datetime
    updated_at: datetime
    user_id: int
    username: str

    class Config:
        from_attributes = True

class BasicResponse(BaseModel):
    success: bool
    message: str
    feedback_id: Optional[int] = None

# 提交反馈
@router.post("", response_model=BasicResponse)
async def create_feedback(
    feedback_data: FeedbackCreate,
    current_user: User = Depends(get_current_user),
    service: FeedbackService = Depends(get_feedback_service)
):
    # 使用服务层创建反馈
    new_feedback = await service.create_feedback(
        user_id=current_user.id,
        feedback_type=feedback_data.type,
        content=feedback_data.content
    )

    return {
        "success": True,
        "message": "反馈提交成功",
        "feedback_id": new_feedback.id
    }

# 获取当前用户的反馈历史
@router.get("/my", response_model=List[FeedbackResponse])
async def get_my_feedback(
    current_user: User = Depends(get_current_user),
    service: FeedbackService = Depends(get_feedback_service)
):
    # 使用服务层获取用户反馈
    return await service.get_user_feedback(user_id=current_user.id)

# 获取所有反馈（仅限管理员）
@router.get("/all", response_model=List[FeedbackResponse])
async def get_all_feedback(
    status: Optional[FeedbackStatus] = None,
    current_user: User = Depends(is_admin),  # 验证管理员权限
    service: FeedbackService = Depends(get_feedback_service)
):
    # 使用服务层获取所有反馈
    return await service.get_all_feedback(status_filter=status)

# 更新反馈状态（仅限管理员）
@router.put("/{feedback_id}", response_model=BasicResponse)
async def update_feedback(
    feedback_id: int,
    feedback_update: FeedbackUpdate,
    current_user: User = Depends(is_admin),  # 验证管理员权限
    service: FeedbackService = Depends(get_feedback_service)
):
    # 使用服务层更新反馈
    updated_feedback = await service.update_feedback(
        feedback_id=feedback_id,
        status=feedback_update.status,
        admin_response=feedback_update.admin_response
    )

    return {
        "success": True,
        "message": "反馈更新成功",
        "feedback_id": updated_feedback.id
    }

rag\src\rag\routes\users.py
"""
用户 API 路由模块

此模块定义了与用户账户相关的 API 端点，
例如获取当前用户信息和更新用户信息。
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional, List
from datetime import datetime
from ..database import get_db, User # 移除了 Query 的导入，假设其已废弃
from ..services.auth_service import AuthService
from ..dependencies import get_current_user, get_auth_service

# 创建路由
router = APIRouter(prefix="/users", tags=["users"])

# 请求和响应模型
class UserUpdateRequest(BaseModel):
    username: Optional[str] = None
    email: Optional[str] = None
    password: Optional[str] = None

class UserResponse(BaseModel):
    user_id: int
    username: str
    email: str
    created_at: datetime

    class Config:
        from_attributes = True

class BasicResponse(BaseModel):
    success: bool
    message: str

# 移除了 QueryItem 和 HistoryResponse Pydantic 模型，假设 /me/history 端点废弃
# 获取当前用户信息路由
@router.get("/me", response_model=UserResponse)
async def get_current_user_info(current_user: User = Depends(get_current_user)):
    return {
        "user_id": current_user.id,
        "username": current_user.username,
        "email": current_user.email,
        "created_at": current_user.created_at
    }

# 更新用户信息路由
@router.put("/me", response_model=BasicResponse)
async def update_user_info(
    user_update: UserUpdateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # 获取要更新的用户
    user = db.query(User).filter(User.id == current_user.id).first()
    if not user:
        raise HTTPException(status_code=404, detail="用户不存在")

    # 如果更新用户名，检查是否重复
    if user_update.username and user_update.username != user.username:
        db_user = db.query(User).filter(User.username == user_update.username).first()
        if db_user:
            raise HTTPException(status_code=400, detail="用户名已被使用")
        user.username = user_update.username

    # 如果更新邮箱，检查是否重复
    if user_update.email and user_update.email != user.email:
        db_email = db.query(User).filter(User.email == user_update.email).first()
        if db_email:
            raise HTTPException(status_code=400, detail="邮箱已被使用")
        user.email = user_update.email

    # 如果更新密码
    if user_update.password:
        auth_service = get_auth_service(db)
        user.hashed_password = auth_service._get_password_hash(user_update.password)

    # 保存更新
    db.commit()

    return {"success": True, "message": "用户信息已更新"}

# 移除了 /me/history 端点，假设其依赖的 Query 模型已废弃

rag\src\rag\routes\__init__.py
"""
API 路由聚合模块

此模块将所有子路由模块 (auth, users, conversation, feedback) 导入并聚合到一个主 APIRouter 实例中，
以便在 FastAPI 应用中统一注册。
"""
from fastapi import APIRouter
from ..routes.auth import router as auth_router
from ..routes.users import router as users_router
from ..routes.conversation import router as conversation_router
from ..routes.feedback import router as feedback_router

router = APIRouter()
router.include_router(auth_router)
router.include_router(users_router)
router.include_router(conversation_router)
router.include_router(feedback_router)

rag\src\rag\services\auth_service.py
"""
认证服务模块

此模块提供与用户认证相关的核心业务逻辑服务。
它封装了用户注册、登录和令牌验证等功能，以及密码处理和JWT令牌处理。
"""

from sqlalchemy.orm import Session
from fastapi import HTTPException, status
from typing import Optional, Dict, Any
from passlib.context import CryptContext
import jwt
from datetime import datetime, timedelta, timezone

from ..database import User
from .. import config


class AuthService:
    """
    认证服务类，提供用户认证和授权的核心业务逻辑
    """

    # 加载环境变量

    # 密码哈希工具
    _pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

    # JWT配置
    _SECRET_KEY = config.SECRET_KEY
    _ALGORITHM = "HS256"
    _ACCESS_TOKEN_EXPIRE_MINUTES = config.ACCESS_TOKEN_EXPIRE_MINUTES

    def __init__(self, db: Session):
        """
        初始化认证服务

        Args:
            db: 数据库会话
        """
        self.db = db

    # 密码处理私有方法
    @classmethod
    def _verify_password(cls, plain_password, hashed_password):
        """
        验证密码

        Args:
            plain_password: 明文密码
            hashed_password: 哈希密码

        Returns:
            bool: 密码是否匹配
        """
        return cls._pwd_context.verify(plain_password, hashed_password)

    @classmethod
    def _get_password_hash(cls, password):
        """
        获取密码哈希

        Args:
            password: 明文密码

        Returns:
            str: 哈希密码
        """
        return cls._pwd_context.hash(password)

    # JWT Token处理私有方法
    @classmethod
    def _create_access_token(cls, data: dict):
        """
        创建访问令牌

        Args:
            data: 要编码的数据

        Returns:
            str: JWT令牌
        """
        to_encode = data.copy()
        if "sub" in to_encode and to_encode["sub"] is not None:
            to_encode["sub"] = str(to_encode["sub"])  # 确保 sub 是字符串
        expire = datetime.now(timezone.utc) + timedelta(minutes=cls._ACCESS_TOKEN_EXPIRE_MINUTES)
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, cls._SECRET_KEY, algorithm=cls._ALGORITHM)
        return encoded_jwt

    @classmethod
    def _verify_token(cls, token: str):
        """
        验证令牌

        Args:
            token: JWT令牌

        Returns:
            int: 用户ID，如果令牌无效则为None
        """
        try:
            payload = jwt.decode(token, cls._SECRET_KEY, algorithms=[cls._ALGORITHM])
            user_id: int = payload.get("sub")
            if user_id is None:
                return None
            return user_id
        except jwt.PyJWTError as e:
            print(f"JWT 解码错误: {e.__class__.__name__} - {e}")  # 打印错误类型和消息
            return None

    async def register_user(self, username: str, email: str, password: str) -> Dict[str, Any]:
        """
        注册新用户

        Args:
            username: 用户名
            email: 电子邮件
            password: 密码

        Returns:
            Dict[str, Any]: 包含成功状态、消息、令牌和用户信息的字典
        """
        # 检查用户名是否已存在
        db_user = self.db.query(User).filter(User.username == username).first()
        if db_user:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="用户名已被注册"
            )

        # 检查邮箱是否已存在
        db_email = self.db.query(User).filter(User.email == email).first()
        if db_email:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="邮箱已被注册"
            )

        # 创建新用户
        hashed_password = self._get_password_hash(password)
        new_user = User(
            username=username,
            email=email,
            hashed_password=hashed_password
        )
        self.db.add(new_user)
        self.db.commit()
        self.db.refresh(new_user)

        # 生成访问令牌
        token = self._create_access_token(data={"sub": new_user.id})

        return {
            "success": True,
            "message": "注册成功",
            "token": token,
            "user_id": new_user.id,
            "username": new_user.username
        }

    async def login_user(self, username: str, password: str) -> Dict[str, Any]:
        """
        用户登录

        Args:
            username: 用户名
            password: 密码

        Returns:
            Dict[str, Any]: 包含成功状态、消息、令牌和用户信息的字典
        """
        # 根据用户名查找用户
        user = self.db.query(User).filter(User.username == username).first()

        # 验证用户和密码
        if not user or not self._verify_password(password, user.hashed_password):
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="用户名或密码错误",
                headers={"WWW-Authenticate": "Bearer"},
            )

        # 生成访问令牌
        token = self._create_access_token(data={"sub": user.id})

        return {
            "success": True,
            "message": "登录成功",
            "token": token,
            "user_id": user.id,
            "username": user.username
        }

    async def get_user_by_token(self, token: str) -> Optional[User]:
        """
        通过令牌获取用户

        Args:
            token: JWT令牌

        Returns:
            Optional[User]: 用户对象，如果令牌无效则为None
        """
        # 验证令牌
        user_id = self._verify_token(token)
        if user_id is None:
            return None

        # 获取用户
        user = self.db.query(User).filter(User.id == user_id).first()
        if user is None or not user.is_active:
            return None

        return user

    async def validate_admin(self, user: User) -> bool:
        """
        验证用户是否为管理员

        Args:
            user: 用户对象

        Returns:
            bool: 如果用户是管理员则为True，否则为False
        """
        # 简单的管理员判断，可以根据实际需求修改（例如添加 is_admin 字段到用户表）
        # 这里暂时使用 ID 为 1 的用户作为管理员
        return user.id == 1


rag\src\rag\services\conversation_service.py
"""
对话服务模块

此模块提供与对话管理相关的核心业务逻辑服务。
它封装了对话管理、消息处理和数据库交互等功能。
"""

from sqlalchemy.orm import Session
from datetime import datetime
import json
from typing import AsyncIterable, Dict, Any, List, Tuple, Optional
from fastapi import HTTPException, status

from ..database import Conversation, Message
from ..rag_pipeline.pipeline import RAGPipeline

class ConversationService:
    """
    对话服务类，提供对话管理功能
    """

    def __init__(
        self,
        db: Session,
        rag_pipeline: Optional[RAGPipeline] = None,
    ):
        """
        初始化对话服务

        Args:
            db: 数据库会话
            rag_pipeline: RAG Pipeline实例，可选，用于处理RAG查询
        """
        self.db = db
        self.rag_pipeline = rag_pipeline

    async def handle_new_message(
        self, conversation_id: int, user_id: int, user_content: str
    ) -> AsyncIterable[Dict[str, Any]]:
        """
        处理现有对话中的新消息，返回流式响应

        Args:
            conversation_id: 对话ID
            user_id: 用户ID
            user_content: 用户消息内容

        Yields:
            Dict[str, Any]: 包含事件类型和数据的字典，用于SSE响应
        """
        # 检查对话是否存在且属于当前用户
        conversation = self.db.query(Conversation).filter(
            Conversation.id == conversation_id, Conversation.user_id == user_id
        ).first()

        if not conversation:
            yield {"event": "error", "data": "对话不存在"}
            return

        # 保存用户消息
        user_message = Message(
            conversation_id=conversation_id,
            role="user",
            content=user_content
        )
        self.db.add(user_message)

        # 更新对话的最后更新时间
        conversation.updated_at = datetime.now()
        self.db.commit()
        self.db.refresh(user_message)

        full_response_content = ""
        try:
            # 获取对话历史记录
            chat_history = await self._get_chat_history(conversation_id)

            # 检查RAG Pipeline是否可用
            if self.rag_pipeline is None:
                # 如果RAG Pipeline不可用，返回错误
                yield {"event": "error", "data": json.dumps({"message": "RAG Pipeline未初始化，无法处理查询"})}
                return

            # 使用RAG Pipeline处理查询
            async for event in self.rag_pipeline.process_query(user_content, chat_history):
                if event["event"] == "message":
                    full_response_content += event["data"]
                yield event

            # 保存助手消息
            if full_response_content:
                await self.save_assistant_message(conversation_id, full_response_content)

        except Exception as e:
            print(f"处理流时出错: {e}")
            # 发送错误事件
            yield {"event": "error", "data": json.dumps({"message": f"处理回复时发生错误: {str(e)}"})}

        # 注意：不要在异步生成器中使用return语句返回值

    async def handle_new_conversation_message(
        self, user_id: int, user_content: str
    ) -> Tuple[int, str, AsyncIterable[Dict[str, Any]]]:
        """
        创建新对话并处理第一条消息，返回对话ID、初始标题和流式响应

        Args:
            user_id: 用户ID
            user_content: 用户消息内容

        Returns:
            Tuple[int, str, AsyncIterable[Dict[str, Any]]]: 包含对话ID、初始标题和事件生成器的元组
        """
        # 检查RAG Pipeline是否可用
        if self.rag_pipeline is None:
            # 如果RAG Pipeline不可用，使用简单的标题生成逻辑
            initial_title = user_content[:15] + "..." if len(user_content) > 15 else user_content

            # 创建一个简单的事件生成器，只返回错误事件
            async def simple_event_generator():
                yield {"event": "error", "data": json.dumps({"message": "RAG Pipeline未初始化，无法处理查询"})}
                yield {"event": "end", "data": ""}

            event_generator_stream = simple_event_generator()
        else:
            # 使用RAG Pipeline生成初始标题和事件流
            initial_title, event_generator_stream = await self.rag_pipeline.process_new_conversation(user_content)

        # 创建新对话，使用临时标题
        new_conversation = Conversation(
            user_id=user_id,
            title=initial_title
        )
        self.db.add(new_conversation)
        self.db.commit()
        self.db.refresh(new_conversation)
        conversation_id = new_conversation.id

        # 保存用户消息
        user_message = Message(
            conversation_id=conversation_id,
            role="user",
            content=user_content
        )
        self.db.add(user_message)
        self.db.commit()

        # 包装事件生成器，添加conversation_start事件和处理后台任务
        async def wrapped_event_generator() -> AsyncIterable[Dict[str, Any]]:
            full_response = ""

            # 先发送包含新对话ID和初始标题的事件
            yield {"event": "conversation_start", "data": json.dumps({"conversation_id": conversation_id, "title": initial_title})}

            # 转发RAG Pipeline生成的事件
            async for event in event_generator_stream:
                yield event

                # 根据事件类型执行不同操作
                if event["event"] == "message":
                    full_response += event["data"]
                elif event["event"] == "end" and full_response:
                    # 流结束，但不在这里保存助手消息，而是由路由层的后台任务处理
                    pass
                elif event["event"] == "title_update":
                    # 标题更新，解析新标题并更新
                    title_data = json.loads(event["data"])
                    generated_title = title_data["title"]
                    await self.update_conversation_title(conversation_id, generated_title)

        return conversation_id, initial_title, wrapped_event_generator()



    async def save_assistant_message(self, conversation_id: int, content: str) -> None:
        """
        保存助手消息到数据库

        Args:
            conversation_id: 对话ID
            content: 助手消息内容
        """
        try:
            assistant_message = Message(
                conversation_id=conversation_id,
                role="assistant",
                content=content
            )
            self.db.add(assistant_message)
            self.db.commit()
            print(f"助手消息 (对话ID: {conversation_id}) 已保存。")
        except Exception as e:
            print(f"保存助手消息失败 (对话ID: {conversation_id}): {e}")
            self.db.rollback()
            raise

    async def update_conversation_title(self, conversation_id: int, title: str) -> None:
        """
        更新对话标题

        Args:
            conversation_id: 对话ID
            title: 新标题
        """
        try:
            conversation = self.db.query(Conversation).filter(Conversation.id == conversation_id).first()
            if conversation:
                conversation.title = title
                self.db.commit()
                print(f"对话 {conversation_id} 标题已更新为 '{title}'")
            else:
                print(f"更新标题失败: 对话 {conversation_id} 不存在")
        except Exception as e:
            print(f"更新标题失败 (对话ID: {conversation_id}): {e}")
            self.db.rollback()
            raise

    async def get_conversation(self, conversation_id: int, user_id: int):
        """
        获取单个对话详情

        Args:
            conversation_id: 对话ID
            user_id: 用户ID

        Returns:
            Conversation: 对话对象
        """
        conversation = self.db.query(Conversation).filter(
            Conversation.id == conversation_id, Conversation.user_id == user_id
        ).first()

        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="对话不存在"
            )

        return conversation

    async def get_user_conversations(self, user_id: int) -> List[Conversation]:
        """
        获取用户的所有对话

        Args:
            user_id: 用户ID

        Returns:
            List[Conversation]: 对话列表
        """
        conversations = self.db.query(Conversation).filter(
            Conversation.user_id == user_id
        ).order_by(Conversation.updated_at.desc()).all()

        return conversations

    async def create_conversation(self, user_id: int, title: str) -> Conversation:
        """
        创建新对话

        Args:
            user_id: 用户ID
            title: 对话标题

        Returns:
            Conversation: 创建的对话对象
        """
        new_conversation = Conversation(
            user_id=user_id,
            title=title
        )
        self.db.add(new_conversation)
        self.db.commit()
        self.db.refresh(new_conversation)
        return new_conversation

    async def update_conversation(self, conversation_id: int, user_id: int, title: str) -> Conversation:
        """
        更新对话标题

        Args:
            conversation_id: 对话ID
            user_id: 用户ID
            title: 新标题

        Returns:
            Conversation: 更新后的对话对象
        """
        conversation = self.db.query(Conversation).filter(
            Conversation.id == conversation_id, Conversation.user_id == user_id
        ).first()

        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="对话不存在"
            )

        conversation.title = title
        self.db.commit()
        self.db.refresh(conversation)
        return conversation

    async def delete_conversation(self, conversation_id: int, user_id: int) -> None:
        """
        删除对话

        Args:
            conversation_id: 对话ID
            user_id: 用户ID
        """
        conversation = self.db.query(Conversation).filter(
            Conversation.id == conversation_id, Conversation.user_id == user_id
        ).first()

        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="对话不存在"
            )

        self.db.delete(conversation)
        self.db.commit()

    # 私有辅助方法
    async def _get_chat_history(self, conversation_id: int) -> str:
        """
        获取对话历史记录

        Args:
            conversation_id: 对话ID

        Returns:
            str: 格式化的对话历史字符串
        """
        messages = self.db.query(Message).filter(
            Message.conversation_id == conversation_id
        ).order_by(Message.created_at).limit(10)  # 限制历史记录条数，避免上下文过长

        chat_history = []
        for msg in messages:
            if msg.role == "user":
                chat_history.append(f"用户: {msg.content}")
            else:
                chat_history.append(f"助手: {msg.content}")

        return "\n".join(chat_history)


rag\src\rag\services\feedback_service.py
"""
反馈服务模块

此模块提供与用户反馈相关的核心业务逻辑服务。
它封装了反馈的创建、查询和管理功能。
"""

from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi import HTTPException, status

from ..database import User, Feedback, FeedbackType, FeedbackStatus


class FeedbackService:
    """
    反馈服务类，提供反馈管理的核心业务逻辑
    """

    def __init__(self, db: Session):
        """
        初始化反馈服务

        Args:
            db: 数据库会话
        """
        self.db = db

    async def create_feedback(self, user_id: int, feedback_type: FeedbackType, content: str) -> Feedback:
        """
        创建新的反馈

        Args:
            user_id: 用户ID
            feedback_type: 反馈类型
            content: 反馈内容

        Returns:
            Feedback: 创建的反馈对象
        """
        try:
            # 创建新的反馈记录
            new_feedback = Feedback(
                user_id=user_id,
                type=feedback_type,
                content=content,
                status=FeedbackStatus.PENDING
            )
            
            self.db.add(new_feedback)
            self.db.commit()
            self.db.refresh(new_feedback)
            
            return new_feedback
        except Exception as e:
            self.db.rollback()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"提交反馈失败: {str(e)}"
            )

    async def get_user_feedback(self, user_id: int) -> List[dict]:
        """
        获取用户的反馈历史

        Args:
            user_id: 用户ID

        Returns:
            List[dict]: 反馈列表，每个反馈包含用户名
        """
        try:
            # 获取用户
            user = self.db.query(User).filter(User.id == user_id).first()
            if not user:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="用户不存在"
                )
            
            # 获取用户的反馈
            feedbacks = self.db.query(Feedback).filter(Feedback.user_id == user_id).all()
            
            # 为每个反馈添加用户名
            result = []
            for feedback in feedbacks:
                feedback_dict = {
                    "id": feedback.id,
                    "type": feedback.type,
                    "content": feedback.content,
                    "status": feedback.status,
                    "admin_response": feedback.admin_response,
                    "created_at": feedback.created_at,
                    "updated_at": feedback.updated_at,
                    "user_id": feedback.user_id,
                    "username": user.username
                }
                result.append(feedback_dict)
            
            return result
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"获取反馈失败: {str(e)}"
            )

    async def get_all_feedback(self, status_filter: Optional[FeedbackStatus] = None) -> List[dict]:
        """
        获取所有反馈（管理员功能）

        Args:
            status_filter: 可选的状态过滤器

        Returns:
            List[dict]: 反馈列表，每个反馈包含用户名
        """
        try:
            query = self.db.query(Feedback).join(User)
            if status_filter:
                query = query.filter(Feedback.status == status_filter)
            
            feedbacks = query.order_by(Feedback.created_at.desc()).all()
            
            # 为每个反馈添加用户名
            result = []
            for feedback in feedbacks:
                feedback_dict = {
                    "id": feedback.id,
                    "type": feedback.type,
                    "content": feedback.content,
                    "status": feedback.status,
                    "admin_response": feedback.admin_response,
                    "created_at": feedback.created_at,
                    "updated_at": feedback.updated_at,
                    "user_id": feedback.user_id,
                    "username": feedback.user.username
                }
                result.append(feedback_dict)
            
            return result
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"获取反馈失败: {str(e)}"
            )

    async def update_feedback(self, feedback_id: int, status: Optional[FeedbackStatus] = None, admin_response: Optional[str] = None) -> Feedback:
        """
        更新反馈状态和管理员回复（管理员功能）

        Args:
            feedback_id: 反馈ID
            status: 新状态，可选
            admin_response: 管理员回复，可选

        Returns:
            Feedback: 更新后的反馈对象
        """
        try:
            # 查找反馈
            feedback = self.db.query(Feedback).filter(Feedback.id == feedback_id).first()
            if not feedback:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="找不到指定反馈"
                )
            
            # 更新状态和响应
            if status:
                feedback.status = status
            if admin_response:
                feedback.admin_response = admin_response
            
            self.db.commit()
            self.db.refresh(feedback)
            
            return feedback
        except HTTPException:
            raise
        except Exception as e:
            self.db.rollback()
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"更新反馈失败: {str(e)}"
            )


rag\src\rag\services\__init__.py
"""
服务层模块

此模块包含应用程序的服务层，负责处理业务逻辑。
服务层位于API路由和数据访问层之间，封装了核心业务流程。
"""

from .conversation_service import ConversationService

__all__ = [
    "ConversationService",
]
